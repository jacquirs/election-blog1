---
title: 'Week 5: Demographics, Turnout, and the First Stage of Our Final Prediction'
author: Jacqui Schlesinger
date: '2024-10-05'
slug: week-5
categories: []
tags: []
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
set.seed(02138)
```

```{r}
####----------------------------------------------------------#
#### Get Libraries 
####----------------------------------------------------------#
library(car)
library(caret)
library(CVXR)
library(foreign)
library(glmnet)
library(haven)
library(janitor)
library(kableExtra)
library(maps)
library(mlr3)
library(randomForest)
library(ranger)
library(RColorBrewer)
library(sf)
library(tidyverse)
library(viridis)
library(dplyr)
library(caret)
library(ranger)
library(janitor)

```

```{r}
####----------------------------------------------------------#
#### Load Datafiles
####----------------------------------------------------------#

# Read popular vote datasets
d_popvote <- read_csv("popvote_1948_2020.csv")
d_state_popvote <- read_csv("state_popvote_1948_2020.csv")

# Read elector distribution dataset
d_ec <- read_csv("corrected_ec_1948_2024.csv")

# Read and merge demographics data
d_demos <- read_csv("demographics.csv")[,-1]

# Read primary turnout data
d_turnout <- read_csv("turnout_1789_2020.csv")
d_state_turnout <- read_csv("state_turnout_1980_2022.csv")
d_state_turnout <- d_state_turnout |> 
  mutate(vep_turnout = as.numeric(str_remove(vep_turnout, "%"))/100) |> 
  select(year, state, vep_turnout)

# Read polling data
d_polls <- read_csv("national_polls_1968-2024.csv")
d_state_polls <- read_csv("state_polls_1968-2024.csv")

# Process state-level polling data
d_pollav_state <- d_state_polls |> 
  group_by(year, state, party) |>
  mutate(mean_pollav = mean(poll_support, na.rm = TRUE)) |>
  top_n(1, poll_date) |> 
  rename(latest_pollav = poll_support) |>
  select(-c(weeks_left, days_left, poll_date, candidate, before_convention)) |>
  pivot_wider(names_from = party, values_from = c(latest_pollav, mean_pollav))
           
d_econ <- read_csv("C:/Users/Jacqui Schlesinger/Documents/election-blog1/fred_econ.csv") |> 
  filter(quarter == 2) # if you run this code please change to location of data
```

```{r}
####----------------------------------------------------------#
#### ANES Data Processing 
####----------------------------------------------------------#

# Read processed ANES data
anes <- read_dta("anes_timeseries_cdf_stata_20220916.dta") # Total ANES Cumulative Data File

anes <- anes |> 
  mutate(year = VCF0004,
         pres_vote = case_when(VCF0704a == 1 ~ 1, 
                               VCF0704a == 2 ~ 2, 
                               .default = NA), 
         # Demographics
         age = VCF0101, 
         gender = VCF0104, # 1 = Male; 2 = Female; 3 = Other
         race = VCF0105b, # 1 = White non-Hispanic; 2 = Black non-Hispanic, 3 == Hispanic; 4 = Other or multiple races, non-Hispanic; 9 = missing/DK
         educ = VCF0110, # 0 = DK; 1 = Less than high school; 2. High school; 3 = Some college; 4 = College+ 
         income = VCF0114, # 1 = 0-16 percentile; 2 = 17-33 percentile; 3 = 34-67; 4 = 68 to 95; 5 = 96 to 100. 
         religion = VCF0128, # 0 = DK; 1 = Protestant; 2 = Catholic; 3 = Jewish; 4 = Other
         attend_church = case_when(
           VCF0004 < 1972 ~ as.double(as.character(VCF0131)),
           TRUE ~ as.double(as.character(VCF0130))
         ), # 1 = every week - regularly; 2 = almost every week - often; 3 = once or twice a month; 4 = a few times a year - seldom; 5 = never ; 6 = no religious preference
         southern = VCF0113,
         region = VCF0113, 
         work_status = VCF0118,
         homeowner = VCF0146, 
         married = VCF0147,
        
         # 7-point PID
         pid7 = VCF0301, # 0 = DK; 1 = Strong Democrat; 2 = Weak Democrat; 3 = Independent - Democrat; 4 = Independent - Independent; 5 = Independent - Republican; 6 = Weak Republican; 7 = Strong Republican
         
         # 3-point PID
         pid3 = VCF0303, # 0 = DK; 1 = Democrats; 2 = Independents; 3 = Republicans. 
         
         # 3-point ideology. 
         ideo = VCF0804 # 0, 9 = DK; 1 = Liberal; 2 = Moderate; 3 = Conservative
         ) |> 
  select(year, pres_vote, age, gender, race, educ, income, religion, attend_church, southern, work_status, homeowner, married, pid7, pid3, ideo)

```

_Note: For this week of class, I was in charge of putting together a presentation of my findings. As a result, this post and the accompanying code as seen on Github contain many more plots than in past weeks, many of which are simply descriptive and exploratory statistics._

Happy 30 days until the election all! This week, I focus on refining my models by introducing the final fundamentals I have learned in class, demographics and turnout data. Additionally, I hone in on the states identified last week through expert prediction to be those I will model exclusively as they are the swing states that could decided the next president of the United States. These states are  **Wisconsin, Pennsylvania, North Carolina, Nevada, Michigan, Georgia, and Arizona**. 

The decision to predict the popular vote in these states alone stems from the expert predictions from organizations like the [Cook Political Report](https://www.cookpolitical.com/) and [Sabato's Crystal Ball](https://centerforpolitics.org/crystalball/), who predict most other states to be safely in either Donald Trump's or Kamala Harris's court for the upcoming election. As such, I count their electoral vote for their respective candidate and move to predict the lesser known outcomes of the seven swing states. 

In this blog post, I begin by exploring the voterfiles for these key states, diving into the specific demographics and those which are most associated with voting behavior. Additionally, I replicate Kim & Zilinsky (2023) findings on the power of demographics to predict turnout and voter share using ANES data, deciding if and how to incorporate this new data point into my model. Building on the elastic net regression ensemble of polling data and economic fundamentals from the last few posts, I explore simulations of the result of the election, also considering random forest methods. 


### Exploring the Voterfile
Voterfile data allow me to see granular information on the demographic characteristics of the voting population of each state. The voterfiles for this post were graciously provided by [Statara Solutions](https://statara.com/). In the following plots, I break down the voterfile data for our seven states of interest

```{r}
####----------------------------------------------------------#
#### Custom Theme
####----------------------------------------------------------#

 barplot_theme <- theme_bw() + 
  theme(
    # Axis text and labels
    axis.title = element_text(face = "bold", size = 12),
    axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
    axis.text.y = element_text(size = 10),
    
    # Legend position and text
    legend.position = "right",
    legend.title = element_text(face = "bold"),
    legend.text = element_text(size = 10),
    
    # Title
    plot.title = element_text(face = "bold", size = 14, hjust = 0.5),
    
    panel.border = element_rect(color = "black"),
    
    # Grid lines
    panel.grid.major = element_line(color = "grey90"),
    panel.grid.minor = element_line(color = "grey95"),
    
    # Background color
    plot.background = element_rect(fill = "white", color = NA)
  )
```


```{r}
####----------------------------------------------------------#
#### Voterfile data loading
####----------------------------------------------------------#

# Read and merge 1% voterfile data into one dataset. 
voterfile.sample.files <- list.files("state_1pc_samples_aug24")

voterfile.complete <- read_csv(paste0("state_1pc_samples_aug24/", voterfile.sample.files[1]))
for (i in 2:length(voterfile.sample.files)) {
  temp <- read_csv(paste0("state_1pc_samples_aug24/",voterfile.sample.files[i]))
  voterfile.complete <- rbind(voterfile.complete, temp)
}

```

```{r}
####----------------------------------------------------------#
#### Pull our 7 state of interest voterfiles
####----------------------------------------------------------#

# Read the CSV files
vf_wi <- read_csv("state_1pc_samples_aug24/WI_sample.csv") %>%
  filter(sii_deceased == 0)

vf_pa <- read_csv("state_1pc_samples_aug24/PA_sample.csv") %>%
  filter(sii_deceased == 0)

vf_nc <- read_csv("state_1pc_samples_aug24/NC_sample.csv") %>%
  filter(sii_deceased == 0)

vf_nv <- read_csv("state_1pc_samples_aug24/NV_sample.csv") %>%
  filter(sii_deceased == 0)

vf_mi <- read_csv("state_1pc_samples_aug24/MI_sample.csv") %>%
  filter(sii_deceased == 0)

vf_ga <- read_csv("state_1pc_samples_aug24/GA_sample.csv") %>%
  filter(sii_deceased == 0)

vf_az <- read_csv("state_1pc_samples_aug24/AZ_sample.csv") %>%
  filter(sii_deceased == 0)

```

```{r}
####----------------------------------------------------------#
#### Voterfile Data Transformations
####----------------------------------------------------------#

# Define the transformation function 
transform_voter_data <- function(data) {
  data %>%
    # Transform sii_race values
    mutate(sii_race = case_when(
      sii_race == "A" ~ "Asian",
      sii_race == "B" ~ "Black or African American",
      sii_race == "H" ~ "Hispanic or Latino",
      sii_race == "W" ~ "White",
      sii_race == "U" ~ "Unknown",
      sii_race == "O" ~ "Other",
      sii_race == "N" ~ "Native American or Alaska Native",
      TRUE ~ sii_race
    )) %>%
    # Transform sii_age_range from sii_age
    mutate(sii_age_range = case_when(
      sii_age >= 18 & sii_age <= 24 ~ "18-24",
      sii_age >= 25 & sii_age <= 34 ~ "25-34",
      sii_age >= 35 & sii_age <= 44 ~ "35-44",
      sii_age >= 45 & sii_age <= 54 ~ "45-54",
      sii_age >= 55 & sii_age <= 64 ~ "55-64",
      sii_age >= 65 ~ "65+",
      TRUE ~ NA_character_
    )) %>%
    # Transform sii_education_level values
    mutate(sii_education_level = case_when(
      sii_education_level == "A" ~ "Less than High School",
      sii_education_level == "B" ~ "High School Graduate",
      sii_education_level == "C" ~ "Some College",
      sii_education_level == "D" ~ "Bachelor's Degree",
      sii_education_level == "E" ~ "Graduate Degree",
      TRUE ~ "Unknown"
    ))
}

# Apply the transformation function to all state datasets
vf_wi <- transform_voter_data(vf_wi)
vf_pa <- transform_voter_data(vf_pa)
vf_nc <- transform_voter_data(vf_nc)
vf_nv <- transform_voter_data(vf_nv)
vf_mi <- transform_voter_data(vf_mi)
vf_ga <- transform_voter_data(vf_ga)
vf_az <- transform_voter_data(vf_az)

```

```{r}
####----------------------------------------------------------#
#### Grouping voterfile data into one dataset
####----------------------------------------------------------#

# Add state names to each dataset
vf_wi <- vf_wi %>% mutate(state = "WI")
vf_pa <- vf_pa %>% mutate(state = "PA")
vf_nc <- vf_nc %>% mutate(state = "NC")
vf_nv <- vf_nv %>% mutate(state = "NV")
vf_mi <- vf_mi %>% mutate(state = "MI")
vf_ga <- vf_ga %>% mutate(state = "GA")
vf_az <- vf_az %>% mutate(state = "AZ")

# Combine all datasets into one
voter_data <- bind_rows(vf_wi, vf_pa, vf_nc, vf_nv, vf_mi, vf_ga, vf_az)
```


```{r}
####----------------------------------------------------------#
#### Gender, race, and age distributions for each state of interest
####----------------------------------------------------------#

# Gender Distribution
gender_dist <- voter_data %>%
  count(state, sii_gender) %>%
  group_by(state) %>%
  mutate(percentage = n / sum(n) * 100) %>%
  ungroup()

ggplot(gender_dist, aes(x = state, y = percentage, fill = sii_gender)) +
  geom_bar(stat = "identity") + 
  geom_text(aes(label = paste0(round(percentage, 1), "%")), position = position_stack(vjust = 0.5), size = 3) +
  coord_flip() +
  labs(title = "Gender Distribution by State", x = "", y = "Percentage") +
  scale_fill_manual(
    values = c("F" = "#FF69B4",
               "M" = "#1E90FF",
               "U" = "#A9A9A9",
               "X" = "#800080"),
    labels = c("F" = "Female", "M" = "Male", "U" = "Unknown", "X" = "Other"),
    name = "Gender") +
  barplot_theme +
  theme(axis.title.x = element_blank(),  
        axis.text.x = element_blank())

```

The gender splits of each state are not surprising, with most being around 50/50. While gender alone may not be able to provide significant and high percentage information on who someone is voting for or whether they turn out, what combined with other demographic variables it is possible it may be a statistically significant predictor, as I will explore below. 


```{r}
# Race Distribution, continued from chunk above
race_dist <- voter_data %>%
  count(state, sii_race) %>%
  group_by(state) %>%
  mutate(percentage = n / sum(n) * 100) %>%
  ungroup()

ggplot(race_dist, aes(x = state, y = percentage, fill = sii_race)) +
  geom_bar(stat = "identity") + 
  geom_text(aes(label = ifelse(percentage >= 3, paste0(round(percentage, 1), "%"), "")), position = position_stack(vjust = 0.5), size = 3) +
  coord_flip() +
  labs(title = "Race Distribution by State", x = "", y = "Percentage") +
  scale_fill_discrete(name = "Race") +
  scale_x_discrete(
    labels = c(
      "Asian" = "Asian",
      "Black or African American" = "Black or\nAfrican American",
      "Hispanic or Latino" = "Hispanic or\nLatino",
      "White" = "White",
      "Unknown" = "Unknown",
      "Other" = "Other",
      "Native American or Alaska Native" = "Native American\nor Alaska Native"
    )
  ) +
  barplot_theme +
  theme(axis.title.x = element_blank(),  
        axis.text.x = element_blank())
```

The distribution of race demographics in the states of interest is more varied than gender. As certain racial demographics may lead to certain political views, which I will attempt to explore later, these different makeups may lead to differing support for the two candidates in these states. The fact that the voters have different characteristics may make it likely that they may support different candidates. It is important also to note that while many states have a large number of white people on the voterfile, large groups of minorities like the hispanic popular of Arizona or African American population of Georgia are often cited on the news as important voting blocks to watch for. However, it is likely that these groups are not a monolith. 

```{r}
# Age Distribution, continued from chunk above
age_dist <- voter_data %>%
   filter(sii_age_range != "NA") %>%
  count(state, sii_age_range) %>%
  group_by(state) %>%
  mutate(percentage = n / sum(n) * 100) %>%
  ungroup()

ggplot(age_dist, aes(x = state, y = percentage, fill = sii_age_range)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = paste0(round(percentage, 1), "%")), position = position_stack(vjust = 0.5), size = 3) +
  coord_flip() +
  labs(title = "Age Range Distribution by State", x = "", y = "Percentage") +
  scale_fill_discrete(name = "Age Groups") +
  barplot_theme +
  theme(axis.title.x = element_blank(),  
        axis.text.x = element_blank())
```

The variation in age may also effect turnout or popular vote outcomes, especially when combined with other demographic variables. Age is consistently found to be a good predictor of turnout in logit regressions of historical data, as in [Matsusaka and Palida (1997)](https://www.jstor.org/stable/30024496). They also find education to be a good predictor. Looking later at [Kim and Zelinsky (2023)](https://link.springer.com/content/pdf/10.1007/s11109-022-09816-z.pdf), I will explore how much of past turnout and popular vote outcomes these and other demographic variables can really explain. 

While looking at demographics alone can tell me about the makeup of each state, it is also important to understand how each group acts. Below, I plot the percent of people in each age x race category that voted in the 2020 general election. For many groups, it surprisingly low, while for others there is incredibly high turnout (though these groups are consistently very small). The height of each bar represents the percentage of people in that age and race category who voted in the 2020 general election.

```{r, out.width = "40%"}
####----------------------------------------------------------#
#### Percentage of people in each age x race group that voted in 2020 general, bar chart by state
####----------------------------------------------------------#

# Function to summarize voting data with percentage
summarize_voting_percentage <- function(df) {
  df %>%
    filter(!is.na(sii_age_range)) %>% 
    mutate(voted_2020g = ifelse(is.na(svi_vh_2020g), 0, 1)) %>%
    group_by(sii_age_range, sii_race) %>%
    summarise(
      total_voters = n(),
      voted_count = sum(voted_2020g, na.rm = TRUE),
      voted_percentage = (voted_count / total_voters) * 100,
      .groups = "drop"
    )
}

# Summarize voting data for each state
summary_wi <- summarize_voting_percentage(vf_wi)
summary_pa <- summarize_voting_percentage(vf_pa)
summary_nc <- summarize_voting_percentage(vf_nc)
summary_nv <- summarize_voting_percentage(vf_nv)
summary_mi <- summarize_voting_percentage(vf_mi)
summary_ga <- summarize_voting_percentage(vf_ga)
summary_az <- summarize_voting_percentage(vf_az)

# what percent of each race x age group voted
# Wisconsin
ggplot(summary_wi, aes(x = sii_age_range, y = voted_percentage, fill = sii_race)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Percentage of Voters by Age Range and Race (Wisconsin), 2020 General", 
       x = "Age Range", 
       y = "Percentage of Voters (%)") +
  scale_fill_discrete(name = "Race") +  # Legend title for race
  theme_minimal()

# Pennsylvania
ggplot(summary_pa, aes(x = sii_age_range, y = voted_percentage, fill = sii_race)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Percentage of Voters by Age Range and Race (Pennsylvania), 2020 General", 
       x = "Age Range", 
       y = "Percentage of Voters (%)") +
  scale_fill_discrete(name = "Race") +
  theme_minimal()

# North Carolina
ggplot(summary_nc, aes(x = sii_age_range, y = voted_percentage, fill = sii_race)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Percentage of Voters by Age Range and Race (North Carolina), 2020 General", 
       x = "Age Range", 
       y = "Percentage of Voters (%)") +
  scale_fill_discrete(name = "Race") +
  theme_minimal()

# Nevada
ggplot(summary_nv, aes(x = sii_age_range, y = voted_percentage, fill = sii_race)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Percentage of Voters by Age Range and Race (Nevada), 2020 General", 
       x = "Age Range", 
       y = "Percentage of Voters (%)") +
  scale_fill_discrete(name = "Race") +
  theme_minimal()

# Michigan
ggplot(summary_mi, aes(x = sii_age_range, y = voted_percentage, fill = sii_race)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Percentage of Voters by Age Range and Race (Michigan), 2020 General", 
       x = "Age Range", 
       y = "Percentage of Voters (%)") +
  scale_fill_discrete(name = "Race") +
  theme_minimal()

# Georgia
ggplot(summary_ga, aes(x = sii_age_range, y = voted_percentage, fill = sii_race)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Percentage of Voters by Age Range and Race (Georgia), 2020 General", 
       x = "Age Range", 
       y = "Percentage of Voters (%)") +
  scale_fill_discrete(name = "Race") +
  theme_minimal()

# Arizona
ggplot(summary_az, aes(x = sii_age_range, y = voted_percentage, fill = sii_race)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Percentage of Voters by Age Range and Race (Arizona), 2020 General", 
       x = "Age Range", 
       y = "Percentage of Voters (%)") +
  scale_fill_discrete(name = "Race") +
  theme_minimal()

```

As is often observed in the literature, there is low turnout in 2020 among young people, but it is worth noting that 18 is the first year they can vote, and the ages in this data are up to date with 2024, making that group significantly smaller in the first place. To understand whether young people actually vote less, it would be best to dive into those currently aged 22-28 to see if and how they voted in 2020. 

Below I also include these graphs as heat maps for ease of reading, but feel free to use whichever works best for your understanding. 

```{r, out.width="30%"}
####----------------------------------------------------------#
#### Percentage of people in each age x race group that voted in 2020 general, heat map by state
####----------------------------------------------------------#

# Wisconsin heatmap
ggplot(summary_wi, aes(x = sii_age_range, y = sii_race, fill = voted_percentage)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "red", high = "forestgreen") +
  geom_text(aes(label = round(voted_percentage, 1)), color = "white") +
  labs(title = "Voting Percentage by Age and Race in Wisconsin, 2020 General", 
       x = "Age Range", 
       y = "Race") +
  theme_minimal() +
  theme(panel.grid = element_blank(), legend.position = "none")

# Pennsylvania heatmap
ggplot(summary_pa, aes(x = sii_age_range, y = sii_race, fill = voted_percentage)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "red", high = "forestgreen") +
  geom_text(aes(label = round(voted_percentage, 1)), color = "white") +
  labs(title = "Voting Percentage by Age and Race in Pennsylvania, 2020 General", 
       x = "Age Range", 
       y = "Race") +
  theme_minimal() +
  theme(panel.grid = element_blank(), legend.position = "none")

# North Carolina heatmap
ggplot(summary_nc, aes(x = sii_age_range, y = sii_race, fill = voted_percentage)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "red", high = "forestgreen") +
  geom_text(aes(label = round(voted_percentage, 1)), color = "white") +
  labs(title = "Voting Percentage by Age and Race in North Carolina, 2020 General", 
       x = "Age Range", 
       y = "Race") +
  theme_minimal() +
  theme(panel.grid = element_blank(), legend.position = "none")

# Nevada heatmap
ggplot(summary_nv, aes(x = sii_age_range, y = sii_race, fill = voted_percentage)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "red", high = "forestgreen") +
  geom_text(aes(label = round(voted_percentage, 1)), color = "white") +
  labs(title = "Voting Percentage by Age and Race in Nevada, 2020 General", 
       x = "Age Range", 
       y = "Race") +
  theme_minimal() +
  theme(panel.grid = element_blank(), legend.position = "none")

# Michigan heatmap
ggplot(summary_mi, aes(x = sii_age_range, y = sii_race, fill = voted_percentage)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "red", high = "forestgreen") +
  geom_text(aes(label = round(voted_percentage, 1)), color = "white") +
  labs(title = "Voting Percentage by Age and Race in Michigan, 2020 General", 
       x = "Age Range", 
       y = "Race") +
  theme_minimal() +
  theme(panel.grid = element_blank(), legend.position = "none")

# Georgia heatmap
ggplot(summary_ga, aes(x = sii_age_range, y = sii_race, fill = voted_percentage)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "red", high = "forestgreen") +
  geom_text(aes(label = round(voted_percentage, 1)), color = "white") +
  labs(title = "Voting Percentage by Age and Race in Georgia, 2020 General", 
       x = "Age Range", 
       y = "Race") +
  theme_minimal() +
  theme(panel.grid = element_blank(), legend.position = "none")

# Arizona heatmap
ggplot(summary_az, aes(x = sii_age_range, y = sii_race, fill = voted_percentage)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "red", high = "forestgreen") +
  geom_text(aes(label = round(voted_percentage, 1)), color = "white") +
  labs(title = "Voting Percentage by Age and Race in Arizona, 2020 General", 
       x = "Age Range", 
       y = "Race") +
  theme_minimal() +
  theme(panel.grid = element_blank(), legend.position = "none")


```

Overall, these demographic explorations provide the context necessary as I move into exploring whether they are good to include in my predictive model.


### Demographics and Prediction
In [Kim and Zilinsky (2023)](https://link.springer.com/content/pdf/10.1007/s11109-022-09816-z.pdf) on the predictive power of demographics on vote choice and party affiliation over time, they find that “models trained on nothing more than demographic labels from public opinion surveys (1952–2020) predict only 63.9% of two-party vote choices and 63.4% of partisan IDs correctly out-of-sample—whether they be based on logistic regressions or tree-based machine learning models.” While they admit that social sorting through demographics appears to have occurred, these trends do not allow the use of demographics to clearly predict someone's voting decisions. Additionally, of the about fifteen demographic variables they test, they find that knowing the party id of a person is more predictive than these together. In this section, I replicate these findings and determine if demographic variables alone are a useful predictor to implement in my election prediction model. 

The data from this analysis comes from the American National Election Studies (ANES), a long-running survey project that collects data on voter attitudes, behaviors, and demographics in the U.S., spanning every presidential election cycle since 1952. Unlike the U.S. Census, which focuses on counting the population and gathering general demographic information, ANES emphasizes understanding political opinions, electoral behavior, and voter psychology, offering insights into how and why people vote in particular ways.

To set up this replication, where my two outcome variables are partisanship and vote choice, I have chosen to use the features age, gender, race, income, education, urbanicity, region, southern, employment, religion, homeownership, and marriage, each split into indicator factors such that the specific values are tested for their importance. The two models I implement to test these factors and their accuracy are logistic regression and random forest models.


```{r}
####----------------------------------------------------------#
#### Prepare pres vote data for logistic regrssion and random forest
####----------------------------------------------------------#

# How well do demographics predict vote choice? 
anes_year <- anes[anes$year == 2016,] |> 
  select(-c(year, pid7, pid3, ideo)) |>
  mutate(
    pres_vote = factor(pres_vote, levels = c(1, 2), labels = c("Democrat", "Republican"))
   # , age = cut(age, 
   #            breaks = c(-Inf, 18, 24, 35, 44, 54, 64, Inf), 
   #            labels = c("Under 18", "18-24", "25-35", "35-44", "45-54", "55-64", "65+"),
   #            right = TRUE),
   #  gender = factor(gender, levels = c(1, 2, 3), labels = c("Male", "Female", "Other")),
   #  race = factor(race, levels = c(1, 2, 3, 4), labels = c("White", "Black", "Hispanic", "Other")),
   #  educ = factor(educ, levels = c(1, 2, 3, 4), labels = c("Less than high school", "High school", "Some college", "College+")),
   #  income = factor(income, levels = c(1, 2, 3, 4, 5), labels = c("0-16 percentile", "17-33 percentile", "34-67 percentile", "68-95 percentile", "96-100 percentile")),
   #  religion = factor(religion, levels = c(0, 1, 2, 3, 4), labels = c("DK", "Protestant", "Catholic", "Jewish", "Other")),
   #  attend_church = factor(attend_church, levels = c(1, 2, 3, 4, 5, 6), labels = c("Every week", "Almost every week", "Once or twice a month", "A few times a year", "Never", "No preference")),
   #  work_status = factor(work_status, levels = c(1, 2, 4, 5, 6, 7, 8),
   #                       labels = c("Working Now", 
   #                                  "Temporarily Laid Off", 
   #                                  "Unemployed", 
   #                                  "Retired", 
   #                                  "Permanently Disabled", 
   #                                  "Homemaker", 
   #                                  "Student")),
   #  southern = factor(southern),
   #  homeowner = factor(homeowner),
   #  married = factor(married)
  ) |> 
  filter(!is.na(pres_vote)) |>
  clean_names()

n_features <- length(setdiff(names(anes_year), "pres_vote"))

set.seed(02138)
train.ind <- createDataPartition(anes_year$pres_vote, p = 0.8, list = FALSE)

anes_train <- anes_year[train.ind,]
anes_test <- anes_year[-train.ind,]

```

Beginning with the logistic regression's ability to predict presidential vote choice, using 2016, below I train a model and then compare its in- and out-of-sample performance in the confusion matrices. 

```{r}
####----------------------------------------------------------#
#### Logistic Regression for pres vote
####----------------------------------------------------------#

# logistic regression
logit_fit <- glm(pres_vote ~ ., family = "binomial", data = anes_train)

# logistic regression summary
logit_summary <- summary(logit_fit)

# convert coefficients
logit_coef <- as.data.frame(logit_summary$coefficients)

# rename columns for kable
colnames(logit_coef) <- c("Estimate", "Std. Error", "z value", "Pr(>|z|)")

# round the coeff estimate
logit_coef$Estimate <- round(logit_coef$Estimate, 4)

# add significance stars manually based on p-values and concatenate to estimate
logit_coef$Estimate <- ifelse(logit_coef$`Pr(>|z|)` < 0.001, paste0(logit_coef$Estimate, "***"), 
                       ifelse(logit_coef$`Pr(>|z|)` < 0.01, paste0(logit_coef$Estimate, "**"), 
                       ifelse(logit_coef$`Pr(>|z|)` < 0.05, paste0(logit_coef$Estimate, "*"), 
                       ifelse(logit_coef$`Pr(>|z|)` < 0.1, paste0(logit_coef$Estimate, "."), 
                                                      logit_coef$Estimate))))

# create a kable table for logistic regression output
logit_coef_table <- logit_coef %>%
  kable("html", caption = "Logistic Regression Model Summary: Vote Share, Logistic") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>%
  add_header_above(c(" " = 1, "Logistic Regression Coefficients" = 4))

logit_coef_table

# in-sample confusion matrix
logit.is <- factor(ifelse(predict(logit_fit, type = "response") > 0.5, 2, 1), 
                   levels = c(1, 2), labels = c("Democrat", "Republican"))

cm.rf.logit.is <- confusionMatrix(logit.is, anes_train$pres_vote)

# in-sample confusion matrix styling
in_sample_cm_table <- cm.rf.logit.is$table %>%
  kable("html", caption = "In-Sample Confusion Matrix: Vote Share, Logistic", align = "c") %>%
  kable_styling(bootstrap_options = c("hover", "condensed", "responsive"),
                full_width = F, position = "center") %>%
  row_spec(0, background = "#f0ad4e") %>%
  column_spec(1, background = "#f0ad4e", bold = T, width = "3cm")

# in-sample accuracy, commented to not print
#in_sample_accuracy <- sum(diag(cm.rf.logit.is$table)) / sum(cm.rf.logit.is$table)
#cat("In-Sample Accuracy:", round(in_sample_accuracy * 100, 2), "%\n")

in_sample_cm_table

# out-of-sample confusion matrix
logit_pred <- factor(ifelse(predict(logit_fit, anes_test, type = "response") > 0.5, 2, 1), 
                     levels = c(1, 2), labels = c("Democrat", "Republican"))

cm.rf.logit.oos <- confusionMatrix(logit_pred, anes_test$pres_vote)

# out-of-sample confusion matrix styling
out_sample_cm_table <- cm.rf.logit.oos$table %>%
  kable("html", caption = "Out-of-Sample Confusion Matrix: Vote Share, Logistic", align = "c") %>%
  kable_styling(bootstrap_options = c("hover", "condensed", "responsive"),
                full_width = F, position = "center") %>%
  row_spec(0, background = "#5bc0de") %>%
  column_spec(1, background = "#5bc0de", bold = T, width = "3cm")

# out-of-sample accuracy, commented to not print
#out_sample_accuracy <- sum(diag(cm.rf.logit.oos$table)) / sum(cm.rf.logit.oos$table)
#cat("Out-of-Sample Accuracy:", round(out_sample_accuracy * 100, 2), "%\n")

out_sample_cm_table

```

The logistic regression is not separated by factors due to errors with the data, but the code for this can be seen in the Github and I will attempt to pursue it at a later date. The accuracy results of this regression mirror that of Kim and Zilinsky, with the demographic variables explaining 67.34% of in sample values and 67.75% out of sample. This can also be viewed in the attached confusion matrices. Of the variables (unfactored) that appear to have a statistically significant impact on vote share, the ones that are at the 5% level of significance include southern, religion, race, education, and gender.  

I can also do a logistic regression for turnout, using NA values in the ANES presidential vote data as non-voters. Note again that this is for 2016, but could be done across years, as Kim and Zilinsky do for vote share and partisanship and get similar predictive power across all years, between 65-70%.

```{r}
####----------------------------------------------------------#
#### Prepare turnout data for logistic regression and random forest
####----------------------------------------------------------#

# turnout data cleaning
anes_year_turnout <- anes[anes$year == 2016,] |> 
  mutate(turnout = factor(ifelse(is.na(pres_vote), 0, 1), 
                          levels = c(0, 1), 
                          labels = c("Did Not Vote", "Voted"))) |> 
  select(-c(year, pid7, pid3, ideo, pres_vote)) |> 
  clean_names()

n_features <- length(setdiff(names(anes_year_turnout), "turnout"))

set.seed(02138)
train.ind.turnout <- sample(1:nrow(anes_year_turnout), size = 0.8 * nrow(anes_year_turnout))

# Split the data into training and test sets
anes_train_turnout <- anes_year_turnout[train.ind.turnout, ]
anes_test_turnout <- anes_year_turnout[-train.ind.turnout, ]

```

```{r}
####----------------------------------------------------------#
#### Logistic regression for turnout
####----------------------------------------------------------#
# logistic regression
logit_fit <- glm(turnout ~ ., family = "binomial", data = anes_train_turnout)

# logistic regression summary
logit_summary <- summary(logit_fit)

# convert coefficients
logit_coef <- as.data.frame(logit_summary$coefficients)

# rename columns for kable
colnames(logit_coef) <- c("Estimate", "Std. Error", "z value", "Pr(>|z|)")

# round the coeff estimate
logit_coef$Estimate <- round(logit_coef$Estimate, 4)

# add significance stars manually based on p-values and concatenate to estimate
logit_coef$Estimate <- ifelse(logit_coef$`Pr(>|z|)` < 0.001, paste0(logit_coef$Estimate, "***"), 
                       ifelse(logit_coef$`Pr(>|z|)` < 0.01, paste0(logit_coef$Estimate, "**"), 
                       ifelse(logit_coef$`Pr(>|z|)` < 0.05, paste0(logit_coef$Estimate, "*"), 
                       ifelse(logit_coef$`Pr(>|z|)` < 0.1, paste0(logit_coef$Estimate, "."), 
                                                      logit_coef$Estimate))))

# create a kable table for logistic regression output
logit_coef_table <- logit_coef %>%
  kable("html", caption = "Logistic Regression Model Summary: Turnout, Logistic") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>%
  add_header_above(c(" " = 1, "logistic regression coefficients" = 4))

logit_coef_table

# in-sample confusion matrix
logit.is <- factor(ifelse(predict(logit_fit, type = "response") > 0.5, 1, 0), 
                   levels = c(0, 1), labels = c("Did Not Vote", "Voted"))

cm.rf.logit.is <- confusionMatrix(logit.is, anes_train_turnout$turnout)

# in-sample confusion matrix styling
in_sample_cm_table <- cm.rf.logit.is$table %>%
  kable("html", caption = "In-Sample Confusion Matrix: Turnout, Logistic", align = "c") %>%
  kable_styling(bootstrap_options = c("hover", "condensed", "responsive"),
                full_width = F, position = "center") %>%
  row_spec(0, background = "#f0ad4e") %>%
  column_spec(1, background = "#f0ad4e", bold = T, width = "3cm")

# in-sample accuracy, commnented to not print
#in_sample_accuracy <- sum(diag(cm.rf.logit.is$table)) / sum(cm.rf.logit.is$table)
#cat("In-Sample Accuracy:", round(in_sample_accuracy * 100, 2), "%\n")

in_sample_cm_table

# out-of-sample confusion matrix
logit_pred <- factor(ifelse(predict(logit_fit, anes_test_turnout, type = "response") > 0.5, 1, 0), 
                   levels = c(0, 1), labels = c("Did Not Vote", "Voted"))

cm.rf.logit.oos <- confusionMatrix(logit_pred, anes_test_turnout$turnout)

# out-of-sample confusion matrix styling
out_sample_cm_table <- cm.rf.logit.oos$table %>%
  kable("html", caption = "Out-of-Sample Confusion Matrix: Turnout, Logistic", align = "c") %>%
  kable_styling(bootstrap_options = c("hover", "condensed", "responsive"),
                full_width = F, position = "center") %>%
  row_spec(0, background = "#5bc0de") %>%
  column_spec(1, background = "#5bc0de", bold = T, width = "3cm")

# out-of-sample accuracy, commented to not print
#out_sample_accuracy <- sum(diag(cm.rf.logit.oos$table)) / sum(cm.rf.logit.oos$table)
#cat("Out-of-Sample Accuracy:", round(out_sample_accuracy * 100, 2), "%\n")

out_sample_cm_table


```

Slightly different than with vote share, it appears that the most statistically significant unfactored predictors of turnout are income, age, and education, which are consistent with the literature. As the confusion matrices show, the in-sample accuracy is 66.48% and out of sample accuracy is 64.99%.

I now transition to a random forest for presidential vote share and turnout, with similar set up to the logistic regressions above. The positive here is the democratic vote share, and I factored each variable such that individual levels can have an impact correctly due to the categorical nature of the data. 

```{r}
####----------------------------------------------------------#
#### Random forest for vote share
####----------------------------------------------------------#
anes <- anes %>%
  mutate(age = case_when(
    age >= 18 & age <= 24 ~ "18-24",
    age >= 25 & age <= 34 ~ "25-34",
    age >= 35 & age <= 44 ~ "35-44",
    age >= 45 & age <= 54 ~ "45-54",
    age >= 55 & age <= 64 ~ "55-64",
    age >= 65 ~ "65+",
    is.na(age) ~ "Unknown"
  )) 

# prepare the dataset
anes_year <- anes[anes$year == 2016,] |> 
  select(-c(year, pid7, pid3, ideo)) |>
  mutate(
    pres_vote = factor(pres_vote, levels = c(1, 2), labels = c("Democrat", "Republican")),
    age = factor(age),                      
    gender = factor(gender),                
    race = factor(race),                    
    educ = factor(educ),                    
    income = factor(income),                
    religion = factor(religion),            
    attend_church = factor(attend_church),  
    southern = factor(southern),            
    work_status = factor(work_status),      
    homeowner = factor(homeowner),          
    married = factor(married)               
  ) |> 
  filter(!is.na(pres_vote)) |>
  filter(!is.na(age)) |>
  clean_names()

# number of features
n_features <- length(setdiff(names(anes_year), "pres_vote"))

# set seed for reproducibility
set.seed(02138)

# create train-test split
train.ind <- createDataPartition(anes_year$pres_vote, p = 0.8, list = FALSE)
anes_train <- anes_year[train.ind,]
anes_test <- anes_year[-train.ind,]

# fit random forest model with importance calculation
rf_fit <- ranger(pres_vote ~ ., 
                 mtry = floor(n_features/3), 
                 respect.unordered.factors = "order", 
                 seed = 02138,
                 classification = TRUE,
                 data = anes_train,
                 importance = "impurity")

# in-sample accuracy
cm.rf.is <- confusionMatrix(rf_fit$predictions, anes_train$pres_vote)

# in-sample confusion matrix
in_sample_cm_table <- cm.rf.is$table %>%
  kable("html", caption = "In-Sample Confusion Matrix: Vote Share, RF", align = "c") %>%
  kable_styling(bootstrap_options = c("hover", "condensed", "responsive"),
                full_width = F, position = "center") %>%
  row_spec(0, background = "#f0ad4e") %>%
  column_spec(1, background = "#f0ad4e", bold = T, width = "3cm")

# out-of-sample accuracy
rf_pred <- predict(rf_fit, data = anes_test)
cm.rf.oos <- confusionMatrix(rf_pred$predictions, anes_test$pres_vote)

# out-of-sample confusion matrix
out_sample_cm_table <- cm.rf.oos$table %>%
  kable("html", caption = "Out-of-Sample Confusion Matrix: Vote Share, RF", align = "c") %>%
  kable_styling(bootstrap_options = c("hover", "condensed", "responsive"),
                full_width = F, position = "center") %>%
  row_spec(0, background = "#5bc0de") %>%
  column_spec(1, background = "#5bc0de", bold = T, width = "3cm")

# feature importance
importance_values <- rf_fit$variable.importance

# create importance_df from importance_values
importance_df <- data.frame(importance = importance_values)
importance_df$feature <- rownames(importance_df)

# order importance_df
importance_df <- importance_df[order(importance_df$importance, decreasing = TRUE),]

# plot feature importance
ggplot(importance_df, aes(x = reorder(feature, importance), y = importance)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(title = "Feature Importance in Random Forest, 2016 Popular Vote Share",
       x = "Features",
       y = "Importance (impurity)") +
  barplot_theme


```
In this random forest, I split the variables into their factors for proper analysis, leading to an in-sample accuracy of 71.65% and out-of-sample accuracy of 70.25%. The confusion matrices for these two cases are shown below. 

```{r}
# plot confusion matrices from last block
in_sample_cm_table

out_sample_cm_table
```


Based on the feature importance analysis (impurity) from the random forest model, age emerged as the most significant factor in predicting voting behavior, followed by race, church attendance, religion, and income. These features had a high influence on whether individuals voted Democrat or Republican, indicating that demographics and social factors played a crucial role in determining voter preference. Gender, southern residence, and homeowner status, while still contributing, had much lower importance values, suggesting that they were less impactful in the model's overall predictions. The findings underscore the importance of understanding voter demographics and personal attributes in political analysis, but the accuracy from splitting the variables by factors was not greatly improved overall.

I can also perform one-hot encoding to view the individual contributions of the levels factored from each variable. A graph of the 25 most important factors but impurity is shown below. 

```{r}
####----------------------------------------------------------#
#### Random forest pre vote by indicator
####----------------------------------------------------------#

# separate the outcome variable before one-hot encoding
pres_vote <- anes_year$pres_vote

# one-hot encode the categorical variables (excluding the outcome)
anes_one_hot <- dummyVars(" ~ .", data = anes_year[, setdiff(names(anes_year), "pres_vote")])
anes_encoded <- data.frame(predict(anes_one_hot, newdata = anes_year))

# add the target variable back
anes_encoded$pres_vote <- pres_vote

# number of features after one-hot encoding
n_features <- length(setdiff(names(anes_encoded), "pres_vote"))

# train-test split
set.seed(02138)
train.ind <- createDataPartition(anes_encoded$pres_vote, p = 0.8, list = FALSE)
anes_train <- anes_encoded[train.ind,]
anes_test <- anes_encoded[-train.ind,]

# fit a new random forest model with one-hot encoded data
rf_fit_one_hot <- ranger(pres_vote ~ ., 
                         mtry = floor(n_features/3), 
                         respect.unordered.factors = "order", 
                         seed = 02138,
                         classification = TRUE,
                         data = anes_train,
                         importance = "impurity")

# get feature importance values
importance_values_one_hot <- rf_fit_one_hot$variable.importance

# create a data frame from importance values
importance_df_one_hot <- data.frame(importance = importance_values_one_hot)
importance_df_one_hot$feature <- rownames(importance_df_one_hot)

# order the importance data frame and select the top 25 features
importance_df_top_25 <- importance_df_one_hot[order(importance_df_one_hot$importance, decreasing = TRUE),][1:25,]

# rename features for plotting using your specified names
importance_df_top_25 <- importance_df_top_25 %>%
  mutate(feature = case_when(
    feature == "race.1" ~ "Race: White",
    feature == "race.2" ~ "Race: Black",
    feature == "educ.4" ~ "Education: College+",
    feature == "religion.1" ~ "Religion: Protestant",
    feature == "attend_church.1" ~ "Attend Church: Every week",
    feature == "attend_church.5" ~ "Attend Church: Never",
    feature == "religion.4" ~ "Religion: Other",
    feature == "income.3" ~ "Income: 34-67 percentile",
    feature == "gender.1" ~ "Gender: Male",
    feature == "southern.2" ~ "Southern: Yes",
    feature == "married.1" ~ "Marital Status: Married",
    feature == "income.4" ~ "Income: 68-95 percentile",
    feature == "southern.1" ~ "Southern: No",
    feature == "gender.2" ~ "Gender: Female",
    feature == "work_status.1" ~ "Work Status: Working Now",
    feature == "religion.2" ~ "Religion: Catholic",
    feature == "educ.2" ~ "Education: High school",
    feature == "educ.3" ~ "Education: Some college",
    feature == "homeowner.1" ~ "Homeowner: Yes",
    feature == "homeowner.2" ~ "Homeowner: No",
    feature == "married.2" ~ "Marital Status: Widowed",
    feature == "married.3" ~ "Marital Status: Divorced",
    feature == "work_status.3" ~ "Work Status: Unemployed",
    feature == "attend_church.4" ~ "Attend Church: A few times a year",
    feature == "income.2" ~ "Income: 17-33 percentile",
    feature == "age.18.24" ~ "Age: 18-24",
    feature == "age.25.34" ~ "Age: 25-34",
    feature == "age.35.44" ~ "Age: 35-44",
    feature == "age.45.54" ~ "Age: 45-54",
    feature == "age.55.64" ~ "Age: 55-64",
    feature == "age.65." ~ "Age: 65+",
    feature == "age.Unknown" ~ "Age: Unknown",
    TRUE ~ feature  # keep the original if no match
  ))

# plot the top 25 features by importance with renamed labels
ggplot(importance_df_top_25, aes(x = reorder(feature, importance), y = importance)) +
  geom_bar(aes(fill = importance), stat = "identity") +
  coord_flip() +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  labs(title = "Top 25 Indicator Feature Importance in Random Forest, 2016 Pop Vote Share",
       x = "Features",
       y = "Importance (impurity)") +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 10),
    legend.position = "none" 
  )

```

This graph gives us insight into which groups were most important at determining vote choice. The better a node is at splitting the data correctly, the more important it is, as measured by impurity. Because the above only looks at 2016, I thought it would also be important to see how much this changes for 2012 and 2020. 

```{r}
####----------------------------------------------------------#
#### Random forest for vote share across multiple years
####----------------------------------------------------------#

# Prepare the dataset for 2012, 2016, and 2020
years <- c(2012, 2016, 2020)
importance_combined_factors <- data.frame()
importance_combined_one_hot <- data.frame()

for (year in years) {
  # Prepare the dataset
  anes_year <- anes[anes$year == year,] |> 
    select(-c(year, pid7, pid3, ideo)) |>
    mutate(
      pres_vote = factor(pres_vote, levels = c(1, 2), labels = c("Democrat", "Republican")),
      age = factor(age),                      
      gender = factor(gender),                
      race = factor(race),                    
      educ = factor(educ),                    
      income = factor(income),                
      religion = factor(religion),            
      attend_church = factor(attend_church),  
      southern = factor(southern),            
      work_status = factor(work_status),      
      homeowner = factor(homeowner),          
      married = factor(married)               
    ) |> 
    filter(!is.na(pres_vote)) |>
    filter(!is.na(age)) |>
    clean_names()
  
  # Number of features
  n_features <- length(setdiff(names(anes_year), "pres_vote"))
  
  # Set seed for reproducibility
  set.seed(02138)
  
  # Create train-test split
  train.ind <- createDataPartition(anes_year$pres_vote, p = 0.8, list = FALSE)
  anes_train <- anes_year[train.ind,]
  anes_test <- anes_year[-train.ind,]
  
  # Fit random forest model with importance calculation for factorized features
  rf_fit <- ranger(pres_vote ~ ., 
                   mtry = floor(n_features/3), 
                   respect.unordered.factors = "order", 
                   seed = 02138,
                   classification = TRUE,
                   data = anes_train,
                   importance = "impurity")
  
  # Feature importance for factorized features
  importance_values <- rf_fit$variable.importance
  importance_df <- data.frame(importance = importance_values)
  importance_df$feature <- rownames(importance_df)
  importance_df <- importance_df[order(importance_df$importance, decreasing = TRUE),]
  
  # Add year information for combined factorized importance
  importance_df$Year <- as.factor(year)
  importance_combined_factors <- rbind(importance_combined_factors, importance_df[1:25,])
  
  # One-hot encoding
  pres_vote <- anes_year$pres_vote
  anes_one_hot <- dummyVars(" ~ .", data = anes_year[, setdiff(names(anes_year), "pres_vote")])
  anes_encoded <- data.frame(predict(anes_one_hot, newdata = anes_year))
  anes_encoded$pres_vote <- pres_vote
  
  # Train-test split for one-hot encoded data
  n_features_one_hot <- length(setdiff(names(anes_encoded), "pres_vote"))
  train.ind_one_hot <- createDataPartition(anes_encoded$pres_vote, p = 0.8, list = FALSE)
  anes_train_one_hot <- anes_encoded[train.ind_one_hot,]
  anes_test_one_hot <- anes_encoded[-train.ind_one_hot,]
  
  # Fit a new random forest model with one-hot encoded data
  rf_fit_one_hot <- ranger(pres_vote ~ ., 
                           mtry = floor(n_features_one_hot/3), 
                           respect.unordered.factors = "order", 
                           seed = 02138,
                           classification = TRUE,
                           data = anes_train_one_hot,
                           importance = "impurity")
  
  # Feature importance values for one-hot encoded features
  importance_values_one_hot <- rf_fit_one_hot$variable.importance
  importance_df_one_hot <- data.frame(importance = importance_values_one_hot)
  importance_df_one_hot$feature <- rownames(importance_df_one_hot)
  
  # Add year information for combined one-hot importance
  importance_df_one_hot$Year <- as.factor(year)
  importance_combined_one_hot <- rbind(importance_combined_one_hot, importance_df_one_hot[order(importance_df_one_hot$importance, decreasing = TRUE)[1:25], ])
}

# Remove rows with NAs
importance_combined_factors <- na.omit(importance_combined_factors)

# Plot the factorized feature importance
ggplot(importance_combined_factors, aes(x = reorder(feature, importance), y = importance, fill = factor(Year))) +
  geom_bar(stat = "identity", position = "dodge") +
  coord_flip() +
  scale_fill_manual(values = c("2012" = "lightblue", "2016" = "orange", "2020" = "lightgreen"), name = NULL) +
  labs(title = "Feature Importance in Random Forest",
       x = "Features",
       y = "Importance (impurity)") +
  barplot_theme +
  theme(
    plot.title = element_text(size = 14),
    legend.title = element_text(size = 10),
    legend.position = "bottom"
  )

# Define a function to rename features
rename_features <- function(df) {
  df %>%
    mutate(feature = case_when(
      feature == "race.1" ~ "Race: White",
      feature == "race.2" ~ "Race: Black",
      feature == "race.3" ~ "Race: Hispanic",
      feature == "race.4" ~ "Race: Other",
      feature == "educ.0" ~ "Education: DK",
      feature == "educ.1" ~ "Education: Less than High School",
      feature == "educ.2" ~ "Education: High School",
      feature == "educ.3" ~ "Education: Some College",
      feature == "educ.4" ~ "Education: College+",
      feature == "income.1" ~ "Income: 0-16 percentile",
      feature == "income.2" ~ "Income: 17-33 percentile",
      feature == "income.3" ~ "Income: 34-67 percentile",
      feature == "income.4" ~ "Income: 68-95 percentile",
      feature == "income.5" ~ "Income: 96-100 percentile",
      feature == "religion.0" ~ "Religion: DK",
      feature == "religion.1" ~ "Religion: Protestant",
      feature == "religion.2" ~ "Religion: Catholic",
      feature == "religion.3" ~ "Religion: Jewish",
      feature == "religion.4" ~ "Religion: Other",
      feature == "attend_church.1" ~ "Attend Church: Every week",
      feature == "attend_church.2" ~ "Attend Church: Almost every week",
      feature == "attend_church.3" ~ "Attend Church: Once or twice a month",
      feature == "attend_church.4" ~ "Attend Church: A few times a year",
      feature == "attend_church.5" ~ "Attend Church: Never",
      feature == "southern.1" ~ "Southern: No",
      feature == "southern.2" ~ "Southern: Yes",
      feature == "work_status.1" ~ "Work Status: Working Now",
      feature == "work_status.2" ~ "Work Status: Not Working",
      feature == "homeowner.1" ~ "Homeowner: Yes",
      feature == "homeowner.2" ~ "Homeowner: No",
      feature == "married.1" ~ "Marital Status: Married",
      feature == "married.2" ~ "Marital Status: Widowed",
      feature == "married.3" ~ "Marital Status: Divorced",
      feature == "work_status.3" ~ "Work Status: Unemployed",
      feature == "gender.1" ~ "Gender: Male",
      feature == "gender.2" ~ "Gender: Female",
      feature == "age.18.24" ~ "Age: 18-24",
      feature == "age.25.34" ~ "Age: 25-34",
      feature == "age.35.44" ~ "Age: 35-44",
      feature == "age.45.54" ~ "Age: 45-54",
      feature == "age.55.64" ~ "Age: 55-64",
      feature == "age.65." ~ "Age: 65+",
      feature == "age.Unknown" ~ "Age: Unknown",
      TRUE ~ feature  # keep the original if no match
    ))
}

# Separate plots for one-hot encoded feature importance for each year
for (year in years) {
  # Filter the one-hot encoded importance data for the current year
  importance_year <- importance_combined_one_hot %>% 
    filter(Year == year) %>% 
    rename_features()  # Apply the renaming function
  
  # Select the top 25 features by importance
  importance_year_top_25 <- importance_year %>%
    top_n(25, importance)

  # Create a separate plot for the current year
  p <- ggplot(importance_year_top_25, aes(x = reorder(feature, importance), y = importance, fill = importance)) +
    geom_bar(stat = "identity") +
    coord_flip() +
    scale_fill_gradient(low = "lightblue", high = "darkblue") +
    labs(title = paste("Top 25 Indicator Feature Importance in Random Forest (", year, ")", sep = ""),
         x = "Features",
         y = "Importance (impurity)") +
    barplot_theme +
    theme(
      plot.title = element_text(size = 10),
      legend.position = "none" 
    )
  
  # Print the plot
  print(p)
}


```

The general feature importance is mostly consistent across years. It does appear that the top 25 most important features are somewhat different, at least in order, over the three most recent elections, further pointing to demographic data as difficult to use in terms of accuracy of prediction. For this reason, I will not be using demographics to directly calculate vote share in my model, though as discussed in the next section it may be helpful for determining 2024 turnout. The full interpretations of these graphs and their important will be more fully explored in my presentation for this week.

Before moving on to my model for the week, I turn to the random forest model of turnout, as I did with presidential vote share. As I discuss below, turnout is hard to measure across years due to no significant 2024 demographic data and other questions on how turnout chnages each year, but for now I look at 2012-2020 to understand the factors that impact it. My turnout model in my simulation will be simple, but these insights can be drawn on for the future to make a more significant turnout model.

```{r}
####----------------------------------------------------------#
#### Random forest for turnout
####----------------------------------------------------------#

# Prepare the dataset
anes_year_turnout_rf <- anes[anes$year == 2016,] |> 
  mutate(turnout = factor(ifelse(is.na(pres_vote), 0, 1), levels = c(0, 1), labels = c("Did Not Vote", "Voted")),
          age = factor(age),  
          gender = factor(gender),                
          race = factor(race),                    
          educ = factor(educ),                    
          income = factor(income),                
          religion = factor(religion),            
          attend_church = factor(attend_church),  
          southern = factor(southern),            
          work_status = factor(work_status),      
          homeowner = factor(homeowner),          
          married = factor(married)
        ) |> 
  select(-c(year, pid7, pid3, ideo, pres_vote)) |> 
  filter(!is.na(turnout)) %>%
  filter(!is.na(age)) %>%
  clean_names()

n_features <- length(setdiff(names(anes_year_turnout_rf), "turnout"))

set.seed(02138)
train.ind.turnout.rf <- sample(1:nrow(anes_year_turnout_rf), size = 0.8 * nrow(anes_year_turnout_rf))

# Split the data into training and test sets
anes_train_turnout_rf <- anes_year_turnout_rf[train.ind.turnout.rf, ]
anes_test_turnout_rf <- anes_year_turnout_rf[-train.ind.turnout.rf, ]

# Fit random forest model with importance calculation
rf_fit_turnout <- ranger(turnout ~ ., 
                         mtry = floor(n_features/3), 
                         respect.unordered.factors = "order", 
                         seed = 02138,
                         classification = TRUE,
                         data = anes_train_turnout_rf,
                         importance = "impurity")

# In-sample accuracy
cm.rf.is.turnout <- confusionMatrix(rf_fit_turnout$predictions, anes_train_turnout_rf$turnout)

# In-sample confusion matrix
in_sample_cm_table_turnout <- cm.rf.is.turnout$table %>%
  kable("html", caption = "In-Sample Confusion Matrix for Turnout: Turnout, RF", align = "c") %>%
  kable_styling(bootstrap_options = c("hover", "condensed", "responsive"),
                full_width = F, position = "center") %>%
  row_spec(0, background = "#f0ad4e") %>%
  column_spec(1, background = "#f0ad4e", bold = T, width = "3cm")

# Out-of-sample accuracy
rf_pred_turnout <- predict(rf_fit_turnout, data = anes_test_turnout_rf)
cm.rf.oos.turnout <- confusionMatrix(rf_pred_turnout$predictions, anes_test_turnout_rf$turnout)

# Out-of-sample confusion matrix
out_sample_cm_table_turnout <- cm.rf.oos.turnout$table %>%
  kable("html", caption = "Out-of-Sample Confusion Matrix for Turnout: Turnout, RF", align = "c") %>%
  kable_styling(bootstrap_options = c("hover", "condensed", "responsive"),
                full_width = F, position = "center") %>%
  row_spec(0, background = "#5bc0de") %>%
  column_spec(1, background = "#5bc0de", bold = T, width = "3cm")

# Feature importance
importance_values_turnout <- rf_fit_turnout$variable.importance

# Create importance_df from importance_values
importance_df_turnout <- data.frame(importance = importance_values_turnout)
importance_df_turnout$feature <- rownames(importance_df_turnout)

# Order importance_df
importance_df_turnout <- importance_df_turnout[order(importance_df_turnout$importance, decreasing = TRUE),]

# Plot feature importance
ggplot(importance_df_turnout, aes(x = reorder(feature, importance), y = importance)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(title = "Feature Importance in Random Forest for Turnout",
       x = "Features",
       y = "Importance (impurity)") +
  barplot_theme
```

The random forest model for turnout in 2016 shows that age, income, and church attendance are the most important predictors of voter turnout. Variables like gender, southern residence, and homeownership have less predictive power in comparison to the top features. Remember, in a random forest, impurity measures how mixed or "impure" the data is at a given node, with lower impurity indicating more homogeneity; feature importance is determined by how much each variable reduces impurity, meaning the most important features are those that most effectively split the data into pure or homogeneous groups.

Looking at the confusion matrices below, I see an accuracy of demographic variables alone in sample of 64.11% and out of sample of 62.41%, performing worse than tha logistic regression and having less predictive power on this than vote share. Note that did not vote is the positive class below. 

```{r}
in_sample_cm_table_turnout

out_sample_cm_table_turnout
```

I can also split across features as indicators of each level of a variable. For 2016, the top 25 are seen below.

```{r}
####----------------------------------------------------------#
#### Random forest for turnout by indicator variable
####----------------------------------------------------------#

# Separate the outcome variable before one-hot encoding
turnout <- anes_year_turnout_rf$turnout

# One-hot encode the categorical variables (excluding the outcome)
anes_one_hot_turnout <- dummyVars(" ~ .", data = anes_year_turnout_rf[, setdiff(names(anes_year_turnout_rf), "turnout")])
anes_encoded_turnout <- data.frame(predict(anes_one_hot_turnout, newdata = anes_year_turnout_rf))

# Add the target variable back
anes_encoded_turnout$turnout <- turnout

# Number of features after one-hot encoding
n_features_turnout <- length(setdiff(names(anes_encoded_turnout), "turnout"))

# Train-test split
set.seed(02138)
train.ind_turnout <- createDataPartition(anes_encoded_turnout$turnout, p = 0.8, list = FALSE)
anes_train_turnout <- anes_encoded_turnout[train.ind_turnout, ]
anes_test_turnout <- anes_encoded_turnout[-train.ind_turnout, ]

# Fit a new random forest model with one-hot encoded data
rf_fit_one_hot_turnout <- ranger(turnout ~ ., 
                                  mtry = floor(n_features_turnout / 3), 
                                  respect.unordered.factors = "order", 
                                  seed = 02138,
                                  classification = TRUE,
                                  data = anes_train_turnout,
                                  importance = "impurity")

# Get feature importance values
importance_values_one_hot_turnout <- rf_fit_one_hot_turnout$variable.importance

# Create a data frame from importance values
importance_df_one_hot_turnout <- data.frame(importance = importance_values_one_hot_turnout)
importance_df_one_hot_turnout$feature <- rownames(importance_df_one_hot_turnout)

# Order the importance data frame and select the top 25 features
importance_df_top_25_turnout <- importance_df_one_hot_turnout[order(importance_df_one_hot_turnout$importance, decreasing = TRUE),][1:25, ]

# Rename features for plotting using your specified names
importance_df_top_25_turnout <- importance_df_top_25_turnout %>%
  mutate(feature = case_when(
      feature == "race.1" ~ "Race: White",
      feature == "race.2" ~ "Race: Black",
      feature == "race.3" ~ "Race: Hispanic",
      feature == "race.4" ~ "Race: Other",
      feature == "educ.0" ~ "Education: DK",
      feature == "educ.1" ~ "Education: Less than High School",
      feature == "educ.2" ~ "Education: High School",
      feature == "educ.3" ~ "Education: Some College",
      feature == "educ.4" ~ "Education: College+",
      feature == "income.1" ~ "Income: 0-16 percentile",
      feature == "income.2" ~ "Income: 17-33 percentile",
      feature == "income.3" ~ "Income: 34-67 percentile",
      feature == "income.4" ~ "Income: 68-95 percentile",
      feature == "income.5" ~ "Income: 96-100 percentile",
      feature == "religion.0" ~ "Religion: DK",
      feature == "religion.1" ~ "Religion: Protestant",
      feature == "religion.2" ~ "Religion: Catholic",
      feature == "religion.3" ~ "Religion: Jewish",
      feature == "religion.4" ~ "Religion: Other",
      feature == "attend_church.1" ~ "Attend Church: Every week",
      feature == "attend_church.2" ~ "Attend Church: Almost every week",
      feature == "attend_church.3" ~ "Attend Church: Once or twice a month",
      feature == "attend_church.4" ~ "Attend Church: A few times a year",
      feature == "attend_church.5" ~ "Attend Church: Never",
      feature == "southern.1" ~ "Southern: No",
      feature == "southern.2" ~ "Southern: Yes",
      feature == "work_status.1" ~ "Work Status: Working Now",
      feature == "work_status.2" ~ "Work Status: Not Working",
      feature == "homeowner.1" ~ "Homeowner: Yes",
      feature == "homeowner.2" ~ "Homeowner: No",
      feature == "married.1" ~ "Marital Status: Married",
      feature == "married.2" ~ "Marital Status: Widowed",
      feature == "married.3" ~ "Marital Status: Divorced",
      feature == "work_status.3" ~ "Work Status: Unemployed",
      feature == "gender.1" ~ "Gender: Male",
      feature == "gender.2" ~ "Gender: Female",
      feature == "age.18.24" ~ "Age: 18-24",
      feature == "age.25.34" ~ "Age: 25-34",
      feature == "age.35.44" ~ "Age: 35-44",
      feature == "age.45.54" ~ "Age: 45-54",
      feature == "age.55.64" ~ "Age: 55-64",
      feature == "age.65." ~ "Age: 65+",
      feature == "age.Unknown" ~ "Age: Unknown",
      TRUE ~ feature  # keep the original if no match
    ))

# Plot the top 25 features by importance with renamed labels
ggplot(importance_df_top_25_turnout, aes(x = reorder(feature, importance), y = importance)) +
  geom_bar(aes(fill = importance), stat = "identity") +
  coord_flip() +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  labs(title = "Top 25 Indicator Feature Importance in Random Forest for Turnout, 2016",
       x = "Features",
       y = "Importance (impurity)") +
  barplot_theme +
  theme(
    plot.title = element_text(size = 10),
    legend.position = "none" 
  )

```

This graph gives us insight into which groups were most important at determining turnout, but not this is not causal. Because the above only looks at 2016, I thought it would also be important to see how much this changes for 2012 and 2020. 

```{r}
####----------------------------------------------------------#
#### Random forest for vote share across multiple years
####----------------------------------------------------------#

# Prepare the dataset for 2012, 2016, and 2020
years <- c(2012, 2016, 2020)
importance_combined_factors <- data.frame()
importance_combined_one_hot <- data.frame()

for (year in years) {
  # Prepare the dataset
  anes_year <- anes[anes$year == year,] |> 
    select(-c(year, pid7, pid3, ideo)) |>
    mutate(
      pres_vote = factor(pres_vote, levels = c(1, 2), labels = c("Democrat", "Republican")),
      age = factor(age),                      
      gender = factor(gender),                
      race = factor(race),                    
      educ = factor(educ),                    
      income = factor(income),                
      religion = factor(religion),            
      attend_church = factor(attend_church),  
      southern = factor(southern),            
      work_status = factor(work_status),      
      homeowner = factor(homeowner),          
      married = factor(married)               
    ) |> 
    filter(!is.na(pres_vote)) |>
    filter(!is.na(age)) %>%
    clean_names()
  
  # Number of features
  n_features <- length(setdiff(names(anes_year), "pres_vote"))
  
  # Set seed for reproducibility
  set.seed(02138)
  
  # Create train-test split
  train.ind <- createDataPartition(anes_year$pres_vote, p = 0.8, list = FALSE)
  anes_train <- anes_year[train.ind,]
  anes_test <- anes_year[-train.ind,]
  
  # Fit random forest model with importance calculation for factorized features
  rf_fit <- ranger(pres_vote ~ ., 
                   mtry = floor(n_features/3), 
                   respect.unordered.factors = "order", 
                   seed = 02138,
                   classification = TRUE,
                   data = anes_train,
                   importance = "impurity")
  
  # Feature importance for factorized features
  importance_values <- rf_fit$variable.importance
  importance_df <- data.frame(importance = importance_values)
  importance_df$feature <- rownames(importance_df)
  importance_df <- importance_df[order(importance_df$importance, decreasing = TRUE),]
  
  # Add year information for combined factorized importance
  importance_df$Year <- as.factor(year)
  importance_combined_factors <- rbind(importance_combined_factors, importance_df[1:25,])
  
  # One-hot encoding
  pres_vote <- anes_year$pres_vote
  anes_one_hot <- dummyVars(" ~ .", data = anes_year[, setdiff(names(anes_year), "pres_vote")])
  anes_encoded <- data.frame(predict(anes_one_hot, newdata = anes_year))
  anes_encoded$pres_vote <- pres_vote
  
  # Train-test split for one-hot encoded data
  n_features_one_hot <- length(setdiff(names(anes_encoded), "pres_vote"))
  train.ind_one_hot <- createDataPartition(anes_encoded$pres_vote, p = 0.8, list = FALSE)
  anes_train_one_hot <- anes_encoded[train.ind_one_hot,]
  anes_test_one_hot <- anes_encoded[-train.ind_one_hot,]
  
  # Fit a new random forest model with one-hot encoded data
  rf_fit_one_hot <- ranger(pres_vote ~ ., 
                           mtry = floor(n_features_one_hot/3), 
                           respect.unordered.factors = "order", 
                           seed = 02138,
                           classification = TRUE,
                           data = anes_train_one_hot,
                           importance = "impurity")
  
  # Feature importance values for one-hot encoded features
  importance_values_one_hot <- rf_fit_one_hot$variable.importance
  importance_df_one_hot <- data.frame(importance = importance_values_one_hot)
  importance_df_one_hot$feature <- rownames(importance_df_one_hot)
  
  # Add year information for combined one-hot importance
  importance_df_one_hot$Year <- as.factor(year)
  importance_combined_one_hot <- rbind(importance_combined_one_hot, importance_df_one_hot[order(importance_df_one_hot$importance, decreasing = TRUE)[1:25], ])
}

# Remove rows with NAs
importance_combined_factors <- na.omit(importance_combined_factors)

# Plot the factorized feature importance
ggplot(importance_combined_factors, aes(x = reorder(feature, importance), y = importance, fill = factor(Year))) +
  geom_bar(stat = "identity", position = "dodge") +
  coord_flip() +
  scale_fill_manual(values = c("2012" = "lightblue", "2016" = "orange", "2020" = "lightgreen"), name = NULL) +
  labs(title = "Feature Importance in Random Forest",
       x = "Features",
       y = "Importance (impurity)") +
  barplot_theme +
  theme(
    plot.title = element_text(size = 14),
    legend.title = element_text(size = 10),
    legend.position = "bottom"
  )

# Define a function to rename features
rename_features <- function(df) {
  df %>%
    mutate(feature = case_when(
      feature == "race.1" ~ "Race: White",
      feature == "race.2" ~ "Race: Black",
      feature == "race.3" ~ "Race: Hispanic",
      feature == "race.4" ~ "Race: Other",
      feature == "educ.0" ~ "Education: DK",
      feature == "educ.1" ~ "Education: Less than High School",
      feature == "educ.2" ~ "Education: High School",
      feature == "educ.3" ~ "Education: Some College",
      feature == "educ.4" ~ "Education: College+",
      feature == "income.1" ~ "Income: 0-16 percentile",
      feature == "income.2" ~ "Income: 17-33 percentile",
      feature == "income.3" ~ "Income: 34-67 percentile",
      feature == "income.4" ~ "Income: 68-95 percentile",
      feature == "income.5" ~ "Income: 96-100 percentile",
      feature == "religion.0" ~ "Religion: DK",
      feature == "religion.1" ~ "Religion: Protestant",
      feature == "religion.2" ~ "Religion: Catholic",
      feature == "religion.3" ~ "Religion: Jewish",
      feature == "religion.4" ~ "Religion: Other",
      feature == "attend_church.1" ~ "Attend Church: Every week",
      feature == "attend_church.2" ~ "Attend Church: Almost every week",
      feature == "attend_church.3" ~ "Attend Church: Once or twice a month",
      feature == "attend_church.4" ~ "Attend Church: A few times a year",
      feature == "attend_church.5" ~ "Attend Church: Never",
      feature == "southern.1" ~ "Southern: No",
      feature == "southern.2" ~ "Southern: Yes",
      feature == "work_status.1" ~ "Work Status: Working Now",
      feature == "work_status.2" ~ "Work Status: Not Working",
      feature == "homeowner.1" ~ "Homeowner: Yes",
      feature == "homeowner.2" ~ "Homeowner: No",
      feature == "married.1" ~ "Marital Status: Married",
      feature == "married.2" ~ "Marital Status: Widowed",
      feature == "married.3" ~ "Marital Status: Divorced",
      feature == "work_status.3" ~ "Work Status: Unemployed",
      feature == "gender.1" ~ "Gender: Male",
      feature == "gender.2" ~ "Gender: Female",
      feature == "age.18.24" ~ "Age: 18-24",
      feature == "age.25.34" ~ "Age: 25-34",
      feature == "age.35.44" ~ "Age: 35-44",
      feature == "age.45.54" ~ "Age: 45-54",
      feature == "age.55.64" ~ "Age: 55-64",
      feature == "age.65." ~ "Age: 65+",
      feature == "age.Unknown" ~ "Age: Unknown",
      TRUE ~ feature  # keep the original if no match
    ))
}

# Separate plots for one-hot encoded feature importance for each year
for (year in years) {
  # Filter the one-hot encoded importance data for the current year
  importance_year <- importance_combined_one_hot %>% 
    filter(Year == year) %>% 
    rename_features()  # Apply the renaming function
  
  # Select the top 25 features by importance
  importance_year_top_25 <- importance_year %>%
    top_n(25, importance)

  # Create a separate plot for the current year
  p <- ggplot(importance_year_top_25, aes(x = reorder(feature, importance), y = importance, fill = importance)) +
    geom_bar(stat = "identity") +
    coord_flip() +
    scale_fill_gradient(low = "lightblue", high = "darkblue") +
    labs(title = paste("Top 25 Indicator Feature Importance in Random Forest (", year, ")", sep = ""),
         x = "Features",
         y = "Importance (impurity)") +
    barplot_theme +
    theme(
      plot.title = element_text(size = 10),
      legend.position = "none" 
    )
  
  # Print the plot
  print(p)
}

```

The general feature importance is somewhat consistent across years. It does appear that the top 25 most important features are somewhat different, at least in order, over the three most recent elections, further pointing to demographic data as difficult to use in terms of accuracy of prediction. Demographics can somewhat help predict turnout, but it does not seem strong enough to warrant strong inclusion in my model. I may include demographics as a predictor of turnout in a future iteration, but as discussed below my model this week uses historical weights. 

### Simulating the Outcome
Simulation is a powerful statistical technique used to model complex systems by generating random samples that represent real-world phenomena. In the context of voting behavior, simulations can help us predict election outcomes by running models that utilize a normal distribution. Prominent organizations like FiveThirtyEight (538) employ these techniques to enhance their election predictions. By simulating, we incorporate uncertainties to better understand potential electoral outcomes.

Calculating voter turnout is inherently challenging due to the myriad of factors that influence voter participation, as seen above. In this simulation, I must address the issue of estimating turnout for 2024, given that the dataset lacks specific demographic information for that year. I also don't know exactly who will turnout out for this election. 

To deal with this, we have several options: estimate state-level demographics from voter files, interpolate Census demographics using a statistical model, or simulate plausible values for turnout based on historical averages or advanced modeling techniques. For this analysis and simplicity, I chose to simulate turnout values by drawing from historical averages, recognizing that a demographic-based method may yield only around 70% accuracy, as demonstrated in earlier sections. 

I present simulated predictions for only the seven states of interest.

```{r}
####----------------------------------------------------------#
#### Simulation data prep
####----------------------------------------------------------#

# Merge data
d <- d_pollav_state %>%
  left_join(d_state_popvote, by = c("year", "state")) %>%
  left_join(d_popvote %>% filter(party == "democrat"), by = "year") %>%
  left_join(d_demos, by = c("year", "state")) %>%
  left_join(d_state_turnout, by = c("year", "state")) %>%
  left_join(d_econ, by = "year") %>% 
  filter(year >= 1980) %>%
  ungroup()

# Sequester states for which we have polling data for 2024 
states.2024 <- unique(d$state[d$year == 2024])
states.2024 <- states.2024[-which(states.2024 == "Nebraska Cd 2")]

# Subset and split data
d <- d %>%
  filter(state %in% states.2024)

d_train <- d %>%
  filter(year < 2024)
d_test <- d %>%
  filter(year == 2024)
```

```{r}
# Example pooled model with turnout and demographics
simp.vars <- c("D_pv2p_lag1", "D_pv2p_lag2", "latest_pollav_DEM", "mean_pollav_DEM",
               "R_pv2p_lag1", "R_pv2p_lag2", "latest_pollav_REP", "mean_pollav_REP",
               "vep_turnout", "GDP_growth_quarterly", "RDPI_growth_quarterly")

mod_lm_dem_simp <- lm(D_pv2p ~ D_pv2p_lag1 + D_pv2p_lag2 + latest_pollav_DEM + mean_pollav_DEM + vep_turnout + GDP_growth_quarterly + RDPI_growth_quarterly,
                      data = d_train)
mod_lm_rep_simp <- lm(R_pv2p ~ R_pv2p_lag1 + R_pv2p_lag2 + latest_pollav_REP + mean_pollav_REP + vep_turnout + GDP_growth_quarterly + RDPI_growth_quarterly,
                      data = d_train)

# Add back in lagged vote share for 2024
t <- d %>%
  filter(year >= 2016) %>%
  arrange(year) %>%
  group_by(state) %>%
  mutate(
    D_pv2p_lag1 = lag(D_pv2p, 1),
    R_pv2p_lag1 = lag(R_pv2p, 1),
    D_pv2p_lag2 = lag(D_pv2p, 2),
    R_pv2p_lag2 = lag(R_pv2p, 2)) %>%
  filter(year == 2024) %>%
  select(state, year, D_pv2p, R_pv2p, D_pv2p_lag1, R_pv2p_lag1, D_pv2p_lag2, R_pv2p_lag2)

# Subset testing data to only relevant variables for our simple model
d_test_simp <- d_test %>%
  select(-c(R_pv2p, R_pv2p_lag1, R_pv2p_lag2, 
            D_pv2p, D_pv2p_lag1, D_pv2p_lag2)) %>%
  left_join(t, by = c("state", "year")) %>%
  select(state, year, all_of(simp.vars))

```

```{r}
# Get average state-level turnout across 2020, 2016, 2012
d_turnout_avg <- d_train %>%
  filter(year %in% c(2020, 2016, 2012)) %>%
  filter(state %in% unique(d_test_simp$state)) %>%
  group_by(state) %>%
  summarize(vep_turnout = mean(vep_turnout, na.rm = TRUE))

```

```{r}
# Make predictions with simple average turnout
d_test_simp <- d_test_simp %>%
  left_join(d_turnout_avg, by = "state") %>%
  select(-vep_turnout.x) %>%
  rename(vep_turnout = vep_turnout.y)

simp_pred_dem <- predict(mod_lm_dem_simp, d_test_simp)
simp_pred_rep <- predict(mod_lm_rep_simp, d_test_simp)
```

```{r}
# Now let's simulate this with varying levels of turnout and get both confidence intervals on our predictions
# and approximate win percentages for each state
m <- 1e4 # Number of simulations
pred.mat <- data.frame(state = rep(d_test_simp$state, m),
                       year = rep(2024, m * length(d_test_simp$state)),
                       vep_turnout = rep(d_turnout_avg$vep_turnout, m),
                       simp_pred_dem = rep(simp_pred_dem, m),
                       simp_pred_rep = rep(simp_pred_rep, m))

j <- 1
for (i in 1:m) {
  vep_turnout <- sapply(d_turnout_avg$vep_turnout, function(mu) {
    rnorm(1, mean = mu, sd = 0.05) # Simulate turnout from Gaussian centered on state average with 5% SD
  })

  d_test_samp <- d_test_simp
  d_test_samp$vep_turnout <- vep_turnout

  simp_pred_dem <- predict(mod_lm_dem_simp, d_test_samp)
  simp_pred_rep <- predict(mod_lm_rep_simp, d_test_samp)

  pred.mat$simp_pred_dem[j:(i * length(states.2024))] <- simp_pred_dem
  pred.mat$simp_pred_rep[j:(i * length(states.2024))] <- simp_pred_rep
  j <- j + length(states.2024) # Hack for filling out matrix
}

```

```{r}
# Calculate confidence intervals for predictions
summary_results <- pred.mat %>%
  group_by(state) %>%
  summarize(
    mean_dem = mean(simp_pred_dem),
    mean_rep = mean(simp_pred_rep),
    sd_dem = sd(simp_pred_dem),
    sd_rep = sd(simp_pred_rep),
    lower_dem = mean_dem - 1.96 * sd_dem,
    upper_dem = mean_dem + 1.96 * sd_dem,
    lower_rep = mean_rep - 1.96 * sd_rep,
    upper_rep = mean_rep + 1.96 * sd_rep
  )

```

```{r}
# Focus on specific states of interest
key_states <- c("Wisconsin", "Pennsylvania", "North Carolina", 
                "Nevada", "Michigan", "Georgia", "Arizona")

final_results <- summary_results %>%
  filter(state %in% key_states) %>%
  select(state, mean_dem, lower_dem, upper_dem, mean_rep, lower_rep, upper_rep)

# Create a styled table with hover effects
final_results %>%
  kable("html", caption = "2024 Election Simulation Results for Key States") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>%
  row_spec(0, background = "#f2f2f2", bold = TRUE) %>%
  add_header_above(c(" " = 1, "Democratic Vote Share" = 3, "Republican Vote Share" = 3), 
                   bold = TRUE, background = "#f2f2f2") %>% 
  column_spec(1, bold = TRUE)

```

In this analysis, I simulated potential election outcomes for 2024 across all states but focused on specific battleground states for detailed results. The simple model utilized historical voting data and polling averages to predict vote shares for both Democratic and Republican candidates. Key variables in the model include D_pv2p_lag1 and D_pv2p_lag2, which capture the lagged Democratic vote shares from the previous two elections, indicating historical voting behavior. latest_pollav_DEM and mean_pollav_DEM reflect the most recent and average polling data for Democrats, showcasing current voter sentiment. Additionally, vep_turnout estimates eligible voter turnout, which is crucial for electoral outcomes, while economic factors like GDP_growth_quarterly and RDPI_growth_quarterly assess the overall economic environment and represent the economic fundamentals carried through from past weeks. This model is a continuation the two variables I have chosen to pursue as useful in my predictions: economic fundamentals and polling data. The simulations were carried out by varying turnout estimates drawn from historical averages, enabling us to incorporate uncertainty in turnout predictions.

In the simulation results, I see that the predicted vote shares for Democratic and Republican candidates exceed 100%. This occurs because the model calculates each party's vote share independently, reflecting distinct voter preferences and turnout estimates. The predictions are also not all statistically significantly different, and within that margin of error the winner is not predicted, so for this week's prediction I will pick the one with the higher mean value as the winner if they are within each other's prediction interval, giving:

Arizona: R
Georgia: D
Michigan: D
Nevada: D
North Carolina: R
Pennsylvania: D
Wisconsin: D

Note that Michigan, Pennsylvania, Wisconsin, and Nevada were statistically significantly different, while others are still indeterminable by the simulations. Below I plot the distribution of values for each in the simulations.

```{r}
# Reshape predictions into long format
pred_long <- pred.mat %>%
  pivot_longer(cols = c(simp_pred_dem, simp_pred_rep), 
               names_to = "party", 
               values_to = "vote_share")

# Filter for the seven states of interest
states_of_interest <- c("Wisconsin", "Pennsylvania", "North Carolina", "Nevada", "Michigan", "Georgia", "Arizona")

pred_long_filtered <- pred_long %>%
  filter(state %in% states_of_interest)

# Plot histograms for the seven states
ggplot(pred_long_filtered, aes(x = vote_share, fill = party)) +
  geom_histogram(position = "identity", alpha = 0.5, bins = 40) +
  scale_fill_manual(values = c("simp_pred_dem" = "blue", "simp_pred_rep" = "red"),
                    labels = c("Democratic Vote Share", "Republican Vote Share")) +
  facet_wrap(~ state) +
  labs(title = "Simulation Outcomes for Key States, 2024 General",
       x = "Vote Share",
       y = "Frequency",
       fill = "Party") +
  barplot_theme +
  theme(axis.text.x = element_text(size = 8),
        axis.text.y = element_text(size = 8))

```

It appears that Democratic vote share is more clustered, while Republican is more distributed with a larger standard deviation. As a result of all of this, I can now make my new prediction, which is different by a state (Arizona to Republican) from my prediction from last week.

**Current Forecast: Harris 292 - Trump 246**


### Data Sources
- Popular Vote Data, national and by state, 1948–2020
- Electoral College Distribution, national, 1948–2024
- Demographics Data, by state
- Primary Turnout Data, national and by state, 1789–2020
- Polling Data, National & State, 1968–2024
- FRED Economic Data, national, 1927-2024
- ANES Data, national
- Voter File Data, by state