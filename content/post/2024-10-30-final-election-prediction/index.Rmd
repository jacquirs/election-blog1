---
title: Final Election Prediction
author: Jacqui Schlesinger
date: '2024-10-30'
slug: final-election-prediction
categories: []
tags: []
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
set.seed(02138)
```

```{r}
####----------------------------------------------------------#
#### Load Libraries
####----------------------------------------------------------#

library(geofacet)
library(ggpubr)
library(ggthemes)
library(haven)
library(kableExtra)
library(maps)
library(mgcv)
library(mgcViz)
library(RColorBrewer)
library(scales)
library(sf)
library(spData)
library(stargazer)
library(tidygeocoder)
library(tidyverse)
library(tigris)
library(tmap)
library(tmaptools)
library(viridis)
library(ggplot2)
library(plotly)
library(ggrepel)
library(car)
library(purrr)
library(broom)
library(knitr)
library(dplyr)
library(tidyr)
library(car)
library(caret)
library(CVXR)
library(glmnet)
library(tidyverse)
library(knitr)
library(kableExtra)
library(plotly)
library(lubridate)

```

```{r, include = FALSE}
####----------------------------------------------------------#
#### Read data
####----------------------------------------------------------#

# Read popular vote datasets
d_popvote <- read_csv("popvote_1948_2020.csv")
d_popvote$party[d_popvote$party == "democrat"] <- "DEM"
d_popvote$party[d_popvote$party == "republican"] <- "REP"

d_state_popvote <- read_csv("state_popvote_1948_2020.csv")
d_state_popvote[d_state_popvote$state == "District of Columbia",]$state <- "District Of Columbia"

# Read elector distribution dataset 
d_ec <- read_csv("corrected_ec_1948_2024.csv")

# Read national polling data
d_polls <- read_csv("national_polls_1968-2024.csv")

# Read state polling data
d_state_polls <- read_csv("state_polls_1968-2024.csv")

# Read state turnout
d_state_turnout <- read_csv("state_turnout_1980_2022.csv")

# Read state-level demographics
d_state_demog <- read_csv("demographics.csv")

# Read county demographics
d_county_demog <- read_csv("county_demographics.csv")

# read economic data
d_econ <- read_csv("fred_econ.csv") |> 
  filter(quarter == 2)

```


BINOMIAL POOLED MODEL

```{r}
# DATA HANDLING

# Prepare polling average data by state and year
d_pollav_state <- d_state_polls |> 
  group_by(year, state, party) |>
  mutate(mean_pollav = mean(poll_support, na.rm = TRUE)) |>
  top_n(1, poll_date) |> 
  rename(latest_pollav = poll_support) |>
  select(-c(weeks_left, days_left, poll_date, candidate, before_convention)) |>
  pivot_wider(names_from = party, values_from = c(latest_pollav, mean_pollav))

# Combine polling average data into the main dataset
d <- d_state_popvote |> 
  left_join(
    d_pollav_state |> 
    select(year, state, 
           latest_pollav_DEM = latest_pollav_DEM, 
           latest_pollav_REP = latest_pollav_REP, 
           mean_pollav_REP = mean_pollav_REP,
           mean_pollav_DEM = mean_pollav_DEM),
    by = c("year", "state")
  ) 

d <- d |> 
  left_join(d_econ, by = "year") %>% 
  ungroup()

# Add lagged vote shares to data.
d <- d |>
  arrange(year) |>
  group_by(state) |>
  mutate(
    D_pv2p_lag1 = lag(D_pv2p, 1),
    R_pv2p_lag1 = lag(R_pv2p, 1),
    D_pv2p_lag2 = lag(D_pv2p, 2),
    R_pv2p_lag2 = lag(R_pv2p, 2)
  ) |>
  filter(year >= 1980)

# Create training and testing datasets.
d_train <- d |> 
  filter(year < 2024) |>
  inner_join(d_state_polls |> filter(weeks_left == 2)) |> 
  mutate(state_abb = state.abb[match(state, state.name)]) |> 
  left_join(d_state_turnout, by = c("state", "year")) |> 
  filter(year >= 1980) 

d_test <- 
  d_pollav_state |> 
    select(year, state, 
           latest_pollav_DEM = latest_pollav_DEM, 
           latest_pollav_REP = latest_pollav_REP, 
           mean_pollav_REP = mean_pollav_REP,
           mean_pollav_DEM = mean_pollav_DEM)
    by = c("year", "state")

d_test <- d_test |>
  left_join(d_econ, by = "year") %>% 
  ungroup()

d_test <- d_test |>
  left_join(d_state_popvote |> select(year, state, D_pv2p, R_pv2p), by = c("year", "state")) |>
  arrange(year) |>
  group_by(state) |>
  mutate(
    D_pv2p_lag1 = lag(D_pv2p, 1),
    R_pv2p_lag1 = lag(R_pv2p, 1),
    D_pv2p_lag2 = lag(D_pv2p, 2),
    R_pv2p_lag2 = lag(R_pv2p, 2)
  ) |>
  filter(year == 2024)

```

```{r}
# DO THE BINOMIAL MODEL

state_glm_forecast <- list()
state_glm_forecast_outputs <- data.frame()

# Democrat model. 
state_glm_forecast$dat_D <- d_train |> filter(party == "DEM")
state_glm_forecast$mod_D <- glm(cbind(votes_D, vep - votes_D) ~ 
                                      latest_pollav_DEM + 
                                      mean_pollav_DEM + 
                                      GDP_growth_quarterly + 
                                      RDPI_growth_quarterly +
                                      D_pv2p_lag1 +
                                      D_pv2p_lag2,
                                      data = state_glm_forecast$dat_D, 
                                      family = binomial(link = "logit"))

# Republican model. 
state_glm_forecast$dat_R <- d_train |> filter(party == "REP")
state_glm_forecast$mod_R <- glm(cbind(votes_R, vep - votes_R) ~ 
                                      latest_pollav_REP + 
                                      mean_pollav_REP + 
                                      GDP_growth_quarterly + 
                                      RDPI_growth_quarterly +
                                      R_pv2p_lag1 +
                                      R_pv2p_lag2, 
                                      data = state_glm_forecast$dat_R, 
                                      family = binomial(link = "logit"))

for (hypo_avg_poll in seq(from = 0, to = 100, by = 10)) { 
    # Democrat prediction. 
    D_pred_vote_prob <- predict(state_glm_forecast$mod_D, 
                                newdata = data.frame(poll_support = hypo_avg_poll,
                                latest_pollav_DEM = mean(state_glm_forecast$dat_R$latest_pollav_DEM),
                                mean_pollav_DEM = mean(state_glm_forecast$dat_R$mean_pollav_DEM),
                                GDP_growth_quarterly = mean(state_glm_forecast$dat_R$GDP_growth_quarterly),
                                RDPI_growth_quarterly = mean(state_glm_forecast$dat_R$RDPI_growth_quarterly), 
                                D_pv2p_lag1 = mean(state_glm_forecast$dat_R$D_pv2p_lag1, na.rm = T), 
                                D_pv2p_lag2 = mean(state_glm_forecast$dat_R$D_pv2p_lag2, na.rm = T)), 
                                se = TRUE, type = "response")
    D_pred_qt <- qt(0.975, df = df.residual(state_glm_forecast$mod_D)) 
    
    # Republican prediction. 
    R_pred_vote_prob <- predict(state_glm_forecast$mod_R, 
                                newdata = data.frame(poll_support = hypo_avg_poll,
                                latest_pollav_REP = mean(state_glm_forecast$dat_R$latest_pollav_REP),
                                mean_pollav_REP = mean(state_glm_forecast$dat_R$mean_pollav_REP),
                                GDP_growth_quarterly = mean(state_glm_forecast$dat_R$GDP_growth_quarterly),
                                RDPI_growth_quarterly = mean(state_glm_forecast$dat_R$RDPI_growth_quarterly), 
                                R_pv2p_lag1 = mean(state_glm_forecast$dat_R$R_pv2p_lag1, na.rm = T), 
                                R_pv2p_lag2 = mean(state_glm_forecast$dat_R$R_pv2p_lag2, na.rm = T)), 
                                se = TRUE, type = "response")
    R_pred_qt <- qt(0.975, df = df.residual(state_glm_forecast$mod_R)) 
    
    # Save predictions. 
    state_glm_forecast_outputs <- rbind(state_glm_forecast_outputs, 
                                        cbind.data.frame(x = hypo_avg_poll,
                                                         y = D_pred_vote_prob$fit * 100,
                                                         ymin = (D_pred_vote_prob$fit - D_pred_qt * D_pred_vote_prob$se.fit) * 100,
                                                         ymax = (D_pred_vote_prob$fit + D_pred_qt * D_pred_vote_prob$se.fit) * 100,
                                                         party = "DEM"),
                                        cbind.data.frame(x = hypo_avg_poll,
                                                         y = R_pred_vote_prob$fit * 100,
                                                         ymin = (R_pred_vote_prob$fit - R_pred_qt * R_pred_vote_prob$se.fit) * 100,
                                                         ymax = (R_pred_vote_prob$fit + R_pred_qt * R_pred_vote_prob$se.fit) * 100,
                                                         party = "REP"))
  }

PA_R_2024 <- d_test %>%
  filter(state == "Pennsylvania") %>%
  select(latest_pollav_REP, mean_pollav_REP, GDP_growth_quarterly, 
         RDPI_growth_quarterly, R_pv2p_lag1, R_pv2p_lag2)

PA_D_2024 <- d_test %>%
  filter(state == "Pennsylvania",) %>%
  select(latest_pollav_DEM, mean_pollav_DEM, GDP_growth_quarterly, 
         RDPI_growth_quarterly, D_pv2p_lag1, D_pv2p_lag2)

R_pred_PA_2024 <- predict(state_glm_forecast$mod_R, newdata = PA_R_2024, se = TRUE, type = "response")
D_pred_PA_2024 <- predict(state_glm_forecast$mod_D, newdata = PA_D_2024, se = TRUE, type = "response")

# Get predicted draw probabilities for D and R from polls
PA_pollav_D <- d_state_polls$poll_support[d_state_polls$state == "Pennsylvania" & d_state_polls$weeks_left == 2 & d_state_polls$party == "DEM"] |> mean(na.rm = TRUE)
PA_pollav_R <- d_state_polls$poll_support[d_state_polls$state == "Pennsylvania" & d_state_polls$weeks_left == 2 & d_state_polls$party == "REP"] |> mean(na.rm = TRUE)
PA_sdpoll_D <- sd(d_state_polls$poll_support[d_state_polls$state == "Pennsylvania" & d_state_polls$weeks_left == 2 & d_state_polls$party == "DEM"] |> na.omit())
PA_sdpoll_R <- sd(d_state_polls$poll_support[d_state_polls$state == "Pennsylvania" & d_state_polls$weeks_left == 2 & d_state_polls$party == "REP"] |> na.omit())

# Simulate Democratic votes using polling averages and standard deviations
sim_D_votes_PA_2024 <- rbinom(n = 10000, size = vep_PA_2024, prob = rnorm(10000, PA_pollav_D / 100, PA_sdpoll_D / 100))

# Simulate Republican votes similarly
sim_R_votes_PA_2024 <- rbinom(n = 10000, size = vep_PA_2024, prob = rnorm(10000, PA_pollav_R / 100, PA_sdpoll_R / 100))

# Calculate vote shares and margins as before
sim_data <- data.frame(
  sim_D_votes_PA = sim_D_votes_PA_2024,
  sim_R_votes_PA = sim_R_votes_PA_2024,
  total_votes = sim_D_votes_PA_2024 + sim_R_votes_PA_2024
) %>%
  mutate(
    D_vote_share = sim_D_votes_PA / total_votes * 100,
    R_vote_share = sim_R_votes_PA / total_votes * 100,
    margin = (R_vote_share - D_vote_share)
  )

# Graph outcomes for both parties
ggplot(sim_data) +
  geom_histogram(aes(x = D_vote_share, fill = "Democratic Vote Share"), alpha = 0.5, bins = 30) +
  geom_histogram(aes(x = R_vote_share, fill = "Republican Vote Share"), alpha = 0.5, bins = 30) +
  scale_fill_manual(values = c("blue", "red")) +
  labs(title = "Simulated Vote Share Distributions for Pennsylvania (2024)",
       x = "Vote Share (%)", y = "Count") +
  theme(legend.title = element_blank())

# calculate the margins and vote distributions predicted
quantiles_margin <- quantile(sim_data$margin, probs = c(0.1, 0.5, 0.9))
quantiles_dem <- quantile(sim_data$D_vote_share, probs = c(0.05, 0.5, 0.95))
quantiles_rep <- quantile(sim_data$R_vote_share, probs = c(0.05, 0.5, 0.95))

# put together the margin
margin_table <- data.frame(
  `Percentile` = c("10th Percentile", "Median", "90th Percentile"),
  `Margin (R - D)` = round(quantiles_margin, 2)
)

# to get median values (commmented out for printing purposes)
(dem_med_PA <- round(quantiles_dem[2], 2))
(rep_med_PA <- round(quantiles_rep[2], 2))

# make kable of margin results
kable(margin_table, col.names = c("Percentile", "Margin (R - D)")) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover")) %>%
  kableExtra::add_header_above(c(" " = 1, "Pennsylvania 2024 Simulated Election Margin" = 2))


```

```{r}
# List of states to analyze
states <- c("Pennsylvania", "North Carolina", "Nevada", "Arizona", "Georgia", "Wisconsin", "Michigan")

# Initialize empty data frames for storing margin results and ggplot objects
margin_results <- data.frame()
median_results <- data.frame()
ggplot_list <- list()

for (state in states) {
    # Prepare the data for Republicans and Democrats based on the state
    R_2024 <- d_test %>%
        filter(state == state) %>%
        select(latest_pollav_REP, mean_pollav_REP, GDP_growth_quarterly, 
               RDPI_growth_quarterly, R_pv2p_lag1, R_pv2p_lag2)

    D_2024 <- d_test %>%
        filter(state == state) %>%
        select(latest_pollav_DEM, mean_pollav_DEM, GDP_growth_quarterly, 
               RDPI_growth_quarterly, D_pv2p_lag1, D_pv2p_lag2)

    # Make predictions
    R_pred <- predict(state_glm_forecast$mod_R, newdata = R_2024, se = TRUE, type = "response")
    D_pred <- predict(state_glm_forecast$mod_D, newdata = D_2024, se = TRUE, type = "response")

    # Get polling averages and standard deviations
    pollav_D <- d_state_polls$poll_support[d_state_polls$state == state & d_state_polls$weeks_left == 2 & d_state_polls$party == "DEM"] |> mean(na.rm = TRUE)
    pollav_R <- d_state_polls$poll_support[d_state_polls$state == state & d_state_polls$weeks_left == 2 & d_state_polls$party == "REP"] |> mean(na.rm = TRUE)
    sdpoll_D <- sd(d_state_polls$poll_support[d_state_polls$state == state & d_state_polls$weeks_left == 2 & d_state_polls$party == "DEM"] |> na.omit())
    sdpoll_R <- sd(d_state_polls$poll_support[d_state_polls$state == state & d_state_polls$weeks_left == 2 & d_state_polls$party == "REP"] |> na.omit())

    # Simulate Democratic votes
    sim_D_votes <- rbinom(n = 10000, size = vep_PA_2024, prob = rnorm(10000, pollav_D / 100, sdpoll_D / 100))
    # Simulate Republican votes
    sim_R_votes <- rbinom(n = 10000, size = vep_PA_2024, prob = rnorm(10000, pollav_R / 100, sdpoll_R / 100))

    # Calculate vote shares and margins
    sim_data <- data.frame(
        sim_D_votes = sim_D_votes,
        sim_R_votes = sim_R_votes,
        total_votes = sim_D_votes + sim_R_votes
    ) %>%
    mutate(
        D_vote_share = sim_D_votes / total_votes * 100,
        R_vote_share = sim_R_votes / total_votes * 100,
        margin = (R_vote_share - D_vote_share)
    )

    # Collect quantiles for margins and vote shares
    quantiles_margin <- quantile(sim_data$margin, probs = c(0.1, 0.5, 0.9))
    quantiles_dem <- quantile(sim_data$D_vote_share, probs = c(0.05, 0.5, 0.95))
    quantiles_rep <- quantile(sim_data$R_vote_share, probs = c(0.05, 0.5, 0.95))

    # Create a margin results data frame
    margin_table <- data.frame(
        State = state,
        `10th Percentile Margin (R - D)` = round(quantiles_margin[[1]], 2),
        `Median Margin (R - D)` = round(quantiles_margin[[2]], 2),
        `90th Percentile Margin (R - D)` = round(quantiles_margin[[3]], 2)
    )
    
    median_table <- data.frame(
        State = state,
        `Democratic Vote Share` = round(quantiles_dem[[2]], 2),
        `Republican Vote Share` = round(quantiles_rep[[2]], 2)
    )

    # Append to the margin results
    margin_results <- rbind(margin_results, margin_table)
    
    median_results <- rbind(median_results, median_table)

    # Create ggplot for vote share distributions
    p <- ggplot(sim_data) +
        geom_histogram(aes(x = D_vote_share, fill = "Democratic Vote Share"), alpha = 0.5, bins = 30) +
        geom_histogram(aes(x = R_vote_share, fill = "Republican Vote Share"), alpha = 0.5, bins = 30) +
        scale_fill_manual(values = c("blue", "red")) +
        labs(title = paste("Simulated Vote Share Distributions for", state, "(2024)"),
             x = "Vote Share (%)", y = "Count") +
        theme(legend.title = element_blank())
    
    # Save the ggplot to the list
    ggplot_list[[state]] <- p
}

# Create a kable for margin results
kable(margin_results, 
      col.names = c("State", "10th Percentile Margin (R - D)", "Median Margin (R - D)", "90th Percentile Margin (R - D)")) %>%
    kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover")) %>%
    kableExtra::add_header_above(c(" " = 1, "2024 Simulated Election Margin by State" = 3))

# Create a kable for median results
kable(median_results, col.names = c("State", "Democratic Vote Share", "Republican Vote Share")) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover")) %>%
  kableExtra::add_header_above(c(" " = 1, "2024 Simulated Median Vote Share by State" = 2))

# Display ggplots for each state
for (plot in ggplot_list) {
    print(plot)
}

```

Results in Harris 270 - Trump 268




ENSEMBLED ENET

SPLIT BY STATE

```{r}
# Create dataset of polling average by week until the election
d_poll_weeks <- d_polls |> 
  group_by(year, party, weeks_left) |>
  summarize(mean_poll_week = mean(poll_support)) |> 
  filter(weeks_left <= 30) |> 
  pivot_wider(names_from = weeks_left, values_from = mean_poll_week) |> 
  left_join(d_popvote, by = c("year", "party"))

# Split into training and testing data based on inclusion or exclusion of 2024. 
d_poll_weeks_train <- d_poll_weeks |> 
  filter(year <= 2020)
d_poll_weeks_test <- d_poll_weeks |> 
  filter(year == 2024)

colnames(d_poll_weeks)[3:33] <- paste0("poll_weeks_left_", 0:30)
colnames(d_poll_weeks_train)[3:33] <- paste0("poll_weeks_left_", 0:30)
colnames(d_poll_weeks_test)[3:33] <- paste0("poll_weeks_left_", 0:30)

# Separate data into X and Y for training
x.train <- d_poll_weeks_train |>
  ungroup() |> 
  select(all_of(paste0("poll_weeks_left_", 1:30))) |> 
  as.matrix()
y.train <- d_poll_weeks_train$pv2p
x.test <- d_poll_weeks_test |>
  ungroup() |> 
  select(all_of(paste0("poll_weeks_left_", 1:30))) |> 
  as.matrix()

# Predict 2024 national pv2p share using elastic-net with polls only 
enet.poll <- cv.glmnet(x = x.train, y = y.train, alpha = 0.5)
lambda.min.enet.poll <- enet.poll$lambda.min
polls.pred <- predict(enet.poll, s = lambda.min.enet.poll, newx = x.test)

# Combine datasets and create vote lags. 
d_combined_super <- d_econ |> 
  left_join(d_poll_weeks, by = "year") |> 
  filter(year %in% c(unique(d_popvote$year), 2024)) |> 
  group_by(party) |> 
  mutate(pv2p_lag1 = lag(pv2p, 1), 
         pv2p_lag2 = lag(pv2p, 2)) |> 
  ungroup() |> 
  mutate(gdp_growth_x_incumbent = GDP_growth_quarterly * incumbent, 
         rdpi_growth_quarterly = RDPI_growth_quarterly * incumbent,
         cpi_x_incumbent = CPI * incumbent,
         unemployment_x_incumbent = unemployment * incumbent,
         sp500_x_incumbent = sp500_close * incumbent) # Generate interaction effects.

# Create fundamentals-only dataset and split into training and test sets
d_fund <- d_combined_super |> 
  select("year", "pv2p", "GDP", "GDP_growth_quarterly", "RDPI", "RDPI_growth_quarterly", "CPI", "unemployment", "sp500_close",
         "incumbent", "gdp_growth_x_incumbent", "rdpi_growth_quarterly", "cpi_x_incumbent", "unemployment_x_incumbent", "sp500_x_incumbent", 
         "pv2p_lag1", "pv2p_lag2") 

x.train.fund <- d_fund |> 
  filter(year <= 2020) |>
  select(-c(year, pv2p)) |> 
  slice(-c(1:9)) |> 
  as.matrix()
y.train.fund <- d_fund |> 
  filter(year <= 2020) |> 
  select(pv2p) |> 
  slice(-c(1:9)) |> 
  as.matrix()
x.test.fund <- d_fund |> 
  filter(year == 2024) |> 
  select(-c(year, pv2p)) |> 
  as.matrix()

# Predict 2024 national pv2p share using elastic-net with economic vars 
enet.fund <- cv.glmnet(x = x.train.fund, y = y.train.fund, intercept = FALSE, alpha = 0.5)
lambda.min.enet.fund <- enet.fund$lambda.min
fund.pred <- predict(enet.fund, s = lambda.min.enet.fund, newx = x.test.fund)

# Define election day
election_day_2024 <- "2024-11-05"
today <- "2024-11-01"
days_left <- as.numeric(as.Date(election_day_2024) - as.Date(today))


# Ensemble 1: Predict based on unweighted (or equally weighted) ensemble model between polls and fundamentals models. 
unweighted.ensemble.pred <- (polls.pred + fund.pred)/2

# Ensemble 2: Weight based on polls mattering closer to November
poll_model_weight <- 1- (1/sqrt(days_left))
fund_model_weight <- 1/sqrt(days_left)

ensemble.2.pred <- polls.pred * poll_model_weight + fund.pred * fund_model_weight

# Ensemble 3. Weight based on fundamentals mattering closer to November
poll_model_weight <- 1/sqrt(days_left)
fund_model_weight <- 1-(1/sqrt(days_left))

ensemble.3.pred <- polls.pred * poll_model_weight + fund.pred * fund_model_weight

# Combine predictions into a dataframe
final_predictions_new <- data.frame(
  Party = c("Harris", "Trump", "Harris", "Trump", "Harris", "Trump"),
  Prediction = c(ensemble.2.pred[1], ensemble.2.pred[2],
                 ensemble.3.pred[1], ensemble.3.pred[2],
                 unweighted.ensemble.pred[1], unweighted.ensemble.pred[2])
)

# Create new data kable
kable_new <- kable(final_predictions_new[, c("Party", "Prediction")], 
                         col.names = c("Party", "Prediction")) %>%
  kable_styling(full_width = F) %>%
  row_spec(0, bold = TRUE, background = "#0072B2", color = "white") %>%
  row_spec(1:4, color = "black") %>%
  pack_rows("Polls More", 1, 2) %>%
  pack_rows("Fundamentals More", 3, 4) %>%
  pack_rows("Unweighted", 5, 6) %>%
  add_header_above(c("Updated Week 3 Ensemble Model Predictions" = 2)) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

kable_new

```

LINEAR REGRESSION

```{r}
# Adjust turnout data
d_state_turnout_clean <- d_state_turnout |> 
  mutate(vep_turnout = as.numeric(str_remove(vep_turnout, "%"))/100) |> 
  select(year, state, vep_turnout)

# Adjust polling data
d_pollav_state <- d_state_polls |> 
  group_by(year, state, party) |>
  mutate(mean_pollav = mean(poll_support, na.rm = TRUE)) |>
  top_n(1, poll_date) |> 
  rename(latest_pollav = poll_support) |>
  select(-c(weeks_left, days_left, poll_date, candidate, before_convention)) |>
  pivot_wider(names_from = party, values_from = c(latest_pollav, mean_pollav))

# Merge data
d <- d_pollav_state %>%
  left_join(d_state_popvote, by = c("year", "state")) %>%
  left_join(d_popvote %>% filter(party == "democrat"), by = "year") %>%
  left_join(d_state_demog, by = c("year", "state")) %>%
  left_join(d_state_turnout_clean, by = c("year", "state")) %>%
  left_join(d_econ, by = "year") %>% 
  filter(year >= 1980) %>%
  ungroup()

# Sequester states for which we have polling data for 2024 
states.2024 <- c("Wisconsin", "Pennsylvania", "North Carolina", "Nevada", "Michigan", "Georgia", "Arizona")

# Subset and split data
d <- d %>%
  filter(state %in% states.2024)

d_train <- d %>%
  filter(year < 2024)
d_test <- d %>%
  filter(year == 2024)

# Pooled model
simp.vars <- c("D_pv2p_lag1", "D_pv2p_lag2", "latest_pollav_DEM", "mean_pollav_DEM",
               "R_pv2p_lag1", "R_pv2p_lag2", "latest_pollav_REP", "mean_pollav_REP",
               "vep_turnout", "GDP_growth_quarterly", "RDPI_growth_quarterly")

mod_lm_dem_simp <- lm(D_pv2p ~ D_pv2p_lag1 + D_pv2p_lag2 + latest_pollav_DEM + mean_pollav_DEM + vep_turnout + GDP_growth_quarterly + RDPI_growth_quarterly,
                      data = d_train)
mod_lm_rep_simp <- lm(R_pv2p ~ R_pv2p_lag1 + R_pv2p_lag2 + latest_pollav_REP + mean_pollav_REP + vep_turnout + GDP_growth_quarterly + RDPI_growth_quarterly,
                      data = d_train)

# Add back in lagged vote share for 2024
t <- d %>%
  filter(year >= 2016) %>%
  arrange(year) %>%
  group_by(state) %>%
  mutate(
    D_pv2p_lag1 = lag(D_pv2p, 1),
    R_pv2p_lag1 = lag(R_pv2p, 1),
    D_pv2p_lag2 = lag(D_pv2p, 2),
    R_pv2p_lag2 = lag(R_pv2p, 2)) %>%
  filter(year == 2024) %>%
  select(state, year, D_pv2p, R_pv2p, D_pv2p_lag1, R_pv2p_lag1, D_pv2p_lag2, R_pv2p_lag2)

# Subset testing data to only relevant variables for our simple model
d_test_simp <- d_test %>%
  select(-c(R_pv2p, R_pv2p_lag1, R_pv2p_lag2, 
            D_pv2p, D_pv2p_lag1, D_pv2p_lag2)) %>%
  left_join(t, by = c("state", "year")) %>%
  filter(state != "Maine Cd 2") %>% 
  select(state, year, all_of(simp.vars))

# CHANGE TO BETTER TUNROUT MODEL
# Get average state-level turnout across 2020, 2016, 2012
d_turnout_avg <- d_train %>%
  filter(year %in% c(2020, 2016, 2012)) %>%
  filter(state %in% unique(d_test_simp$state)) %>%
  filter(state != "Maine Cd 2") %>% 
  group_by(state) %>%
  summarize(vep_turnout = mean(vep_turnout, na.rm = TRUE))

# Make predictions with simple average turnout
d_test_simp <- d_test_simp %>%
  left_join(d_turnout_avg, by = "state") %>%
  select(-vep_turnout.x) %>%
  rename(vep_turnout = vep_turnout.y)

simp_pred_dem <- predict(mod_lm_dem_simp, d_test_simp)
simp_pred_rep <- predict(mod_lm_rep_simp, d_test_simp)

# Now let's simulate this with varying levels of turnout and get both confidence intervals on our predictions
# and approximate win percentages for each state
m <- 1e4 # Number of simulations
pred.mat <- data.frame(state = rep(d_test_simp$state, m),
                       # year = rep(2024, m * length(d_test_simp$state)),
                       year = rep(2024, length(d_test_simp$state)*m),
                       vep_turnout = rep(d_turnout_avg$vep_turnout, m),
                       simp_pred_dem = rep(simp_pred_dem, m),
                       simp_pred_rep = rep(simp_pred_rep, m))

j <- 1
for (i in 1:m) {
  vep_turnout <- sapply(d_turnout_avg$vep_turnout, function(mu) {
    rnorm(1, mean = mu, sd = 0.05) # Simulate turnout from Gaussian centered on state average with 5% SD
  })

  d_test_samp <- d_test_simp
  d_test_samp$vep_turnout <- vep_turnout

  simp_pred_dem <- predict(mod_lm_dem_simp, d_test_samp)
  simp_pred_rep <- predict(mod_lm_rep_simp, d_test_samp)

  pred.mat$simp_pred_dem[j:(i * length(states.2024))] <- simp_pred_dem
  pred.mat$simp_pred_rep[j:(i * length(states.2024))] <- simp_pred_rep
  j <- j + length(states.2024) # Hack for filling out matrix
}

# Calculate confidence intervals for predictions
summary_results <- pred.mat %>%
  group_by(state) %>%
  summarize(
    mean_dem = mean(simp_pred_dem),
    mean_rep = mean(simp_pred_rep),
    sd_dem = sd(simp_pred_dem),
    sd_rep = sd(simp_pred_rep),
    lower_dem = mean_dem - 1.96 * sd_dem,
    upper_dem = mean_dem + 1.96 * sd_dem,
    lower_rep = mean_rep - 1.96 * sd_rep,
    upper_rep = mean_rep + 1.96 * sd_rep
  )

# Focus on specific states of interest
key_states <- c("Wisconsin", "Pennsylvania", "North Carolina", 
                "Nevada", "Michigan", "Georgia", "Arizona")

final_results <- summary_results %>%
  filter(state %in% key_states) %>%
  select(state, mean_dem, lower_dem, upper_dem, mean_rep, lower_rep, upper_rep)

# Create a styled table with hover effects
final_results %>%
  kable("html", caption = "2024 Election Upated Simulation Results for Key States") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>%
  row_spec(0, background = "#f2f2f2", bold = TRUE) %>%
  add_header_above(c(" " = 1, "Democratic Vote Share" = 3, "Republican Vote Share" = 3), 
                   bold = TRUE, background = "#f2f2f2") %>% 
  column_spec(1, bold = TRUE)

# Reshape predictions into long format
pred_long <- pred.mat %>%
  pivot_longer(cols = c(simp_pred_dem, simp_pred_rep), 
               names_to = "party", 
               values_to = "vote_share")

# Filter for the seven states of interest
states_of_interest <- c("Wisconsin", "Pennsylvania", "North Carolina", "Nevada", "Michigan", "Georgia", "Arizona")

pred_long_filtered <- pred_long %>%
  filter(state %in% states_of_interest)

# Plot histograms for the seven states
ggplot(pred_long_filtered, aes(x = vote_share, fill = party)) +
  geom_histogram(position = "identity", alpha = 0.5, bins = 40) +
  scale_fill_manual(values = c("simp_pred_dem" = "blue", "simp_pred_rep" = "red"),
                    labels = c("Democratic Vote Share", "Republican Vote Share")) +
  facet_wrap(~ state) +
  labs(title = "Updated Simulation Outcomes for Key States, 2024 General",
       x = "Vote Share",
       y = "Frequency",
       fill = "Party") +
  barplot_theme +
  theme(axis.text.x = element_text(size = 8),
        axis.text.y = element_text(size = 8))

```


