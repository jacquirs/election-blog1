---
title: 'Week 2: Economic Fundamentals and Regression-Based Prediction'
author: Jacqui Schlesinger
date: '2024-09-13'
slug: week-2
categories: []
tags: []
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{r, results = 'hide'}
# Load libraries
library(ggplot2)
library(maps)
library(tidyverse)
library(plotly)
library(ggrepel)
library(car)
library(readxl)
library(purrr)
library(broom)
library(knitr)
library(kableExtra)
library(dplyr)
library(tidyr)

```

```{r}
####----------------------------------------------------------#
#### Read, merge, and process data
####----------------------------------------------------------#

# Load popular vote data 
d_popvote <- read_csv("C:/Users/Jacqui Schlesinger/Documents/election-blog1/popvote_1948-2020.csv") # if you run this code please change to location of data

# Load economic data from FRED: https://fred.stlouisfed.org. 
# Variables, units, & ranges: 
# GDP, billions $, 1947-2024
# GDP_growth_quarterly, %
# RDPI, $, 1959-2024
# RDPI_growth_quarterly, %
# CPI, $ index, 1947-2024
# unemployment, %, 1948-2024
# sp500_, $, 1927-2024 
d_fred <- read_csv("C:/Users/Jacqui Schlesinger/Documents/election-blog1/fred_econ.csv")

# Load economic data from the BEA: https://apps.bea.gov/iTable/?reqid=19&step=2&isuri=1&categories=survey#eyJhcHBpZCI6MTksInN0ZXBzIjpbMSwyLDMsM10sImRhdGEiOltbImNhdGVnb3JpZXMiLCJTdXJ2ZXkiXSxbIk5JUEFfVGFibGVfTGlzdCIsIjI2NCJdLFsiRmlyc3RfWWVhciIsIjE5NDciXSxbIkxhc3RfWWVhciIsIjIwMjQiXSxbIlNjYWxlIiwiMCJdLFsiU2VyaWVzIiwiUSJdXX0=.
# GDP, 1947-2024 (all)
# GNP
# RDPI
# Personal consumption expenditures
# Goods
# Durable goods
# Nondurable goods
# Services 
# Population (midperiod, thousands)
d_bea <- read_csv("C:/Users/Jacqui Schlesinger/Documents/election-blog1/bea_econ.csv") |> 
  rename(year = "Year",
         quarter = "Quarter", 
         gdp = "Gross domestic product", 
         gnp = "Gross national product", 
         dpi = "Disposable personal income", 
         consumption = "Personal consumption expenditures", 
         goods = "Goods", 
         durables = "Durable goods", 
         nondurables = "Nondurable goods", 
         services = "Services", 
         pop = "Population (midperiod, thousands)")

# Filter and merge data. 
d_inc_econ <- d_popvote |> 
  filter(incumbent_party == TRUE) |> 
  select(year, pv, pv2p, winner) |> 
  left_join(d_fred |> filter(quarter == 2)) |> 
  left_join(d_bea |> filter(quarter == "Q2") |> select(year, dpi))
  # N.B. two different sources of data to use, FRED & BEA. 
  # We are using second-quarter data since that is the latest 2024 release. 

# Remove 2020 data
d_inc_econ_2 <- d_inc_econ |>
  filter(year != 2020)

```

```{r}
####----------------------------------------------------------#
#### Create a theme
####----------------------------------------------------------#

# Create custom theme for line plots
scatterplot_theme <- theme_bw() + 
    theme(panel.border = element_blank(),
          plot.title = element_text(size = 15, hjust = 0.5), 
          axis.text = element_text(size = 12),
          axis.line = element_line(colour = "black"))

# Create custom theme for maps 
maps_theme <- theme_bw() + 
    theme(panel.border = element_blank(),     
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          axis.title = element_blank(),
          axis.text = element_blank(),
          axis.ticks = element_blank(),
          plot.title = element_text(size = 12),
          strip.text = element_text(size = 9),
          legend.position = "right",
          legend.text = element_text(size = 8),
          legend.title = element_text(size = 9))
```


_In this blog, I will attempt to forecast the outcome of the 2024 US presidential election. As a part of Gov 1347: Election Analytics, I will use data from a variety of sources to develop a compelling model._

This week, I will assess how economic fundamentals at the national and state levels predict the incumbent party's national popular vote percentage. To do so, I will evaluate various predictive models using national economic indicators and compare these to models based on state-level data to understand the impact of sociotropic (group well-being focused) versus individual voting. 

Economic fundamentals, tracked by the St. Louis Federal Reserve ([FRED](https://fred.stlouisfed.org/)) and Bureau of Economic Analysis ([BEA](https://www.bea.gov/)) back to the early-twentieth century, offer insights into voter behavior and election forecasting. Today's analysis will focus on the national two-way popular vote percentage for the incumbent party as the chosen dependent variable, therefore overcoming third-parties. Incumbents are linked to the economic conditions leading up to elections, which can [directly impact their vote share](https://www.journals.uchicago.edu/doi/abs/10.1086/693908). This results retrospective voting, where past data or experience to inform voters' decisions about a particular candidate. The applicability of the retrospective voting hypothesis will be explored below.


### Assumptions and Decisions
Before this analysis, I will note decisions I have made in restricting the data. I will analyze elections from 1952 to 2016, due to applicability issues of older data, excluding 2020 due to pandemic-induced economic anomalies which could skew predictions. The 2020 results may effect the 2024 outcome in other uncontrolled ways, creating more bias in my model. This range might also be too broad due to changes in voter demographics, such as those influenced by the [Voting Rights Act of 1965](https://www.archives.gov/milestone-documents/voting-rights-act), and voting behavior over time, with retrospective economic voting potentially dropping in importance. Future iterations of the model will weigh election years to adjust for these factors and reevaluate the impact of 2020 results.


### National Economic Predictors
National economic variables and their relationship to popular vote outcomes can define the economic model of voting behavior. Looking specifically at quarter two results in election years across of variety of government measured variables-- quarter two due research [compiled by Achen and Bartels](https://muse-jhu-edu.ezp-prod1.hul.harvard.edu/book/64646) on the retrospective model noting that recent events have more impact on voting decisions-- I will determine which predictors provide worthwhile insight and could be used to predict 2024 results. The variables I will examine include 

_GDP: gross domestic product in billions_
_GDP Growth Q2: quarterly GDP growth in Q2_
_RDPI: real disposable personal income in dollars_
_RDPI Growth Q2: quarterly RDPI growth in Q2_
_CPI: consumer price index in dollars_
_Unemployment: unemployment rate as a percent_
_SP500 close, open, high, low, adjusted close, and volume: SP500 values in dollars_
_DPI: disposable personal income_

Per in-class explorations of the best predictive economic fundamentals, I will begin by examining bivariate regression models using GDP growth and RDPI growth quarterly. 

```{r}
####----------------------------------------------------------#
#### National Variable Scatterplot: Q2 GDP growth
####----------------------------------------------------------#

# fit a bivariate OLS to the data
reg_econ_2 <- lm(pv2p ~ GDP_growth_quarterly, 
                         data = d_inc_econ_2)

# scatterplot of GDP growth versus pv2p
scatterplot_gdp_growth <- d_inc_econ_2 |> 
  ggplot(aes(x = GDP_growth_quarterly, y = pv2p, label = year)) + 
  geom_text(aes(label = year, text = paste("GDP Growth:", round(GDP_growth_quarterly,3), "<br>Popular Vote:", round(pv2p,3))), 
            nudge_x = 0.02, nudge_y = 0.02, check_overlap = TRUE) + 
  geom_smooth(method = "lm", formula = y ~ x, color = "green", fill = "lightgreen", show.legend = FALSE) +
  geom_hline(yintercept = 50, lty = 2) + 
  geom_vline(xintercept = 0.01, lty = 2) + 
  labs(x = "Second Quarter GDP Growth (%)", 
       y = "Incumbent Party's National Popular Vote Share", 
       title = "Q2 GDP Growth vs Incumbent National Popular Vote Share") + 
  scatterplot_theme

# convert to plotly
scatterplot_interactive <- ggplotly(scatterplot_gdp_growth, tooltip = "text")

# handle odd smooth highlighting 
scatterplot_interactive <- scatterplot_interactive %>%
  style(
    hoverinfo = "text", 
    traces = which(sapply(scatterplot_interactive$x$data, function(trace) "text" %in% names(trace)))
  ) %>%
  layout(
    hovermode = "closest"
  )

scatterplot_interactive
```

```{r, include = FALSE}
####----------------------------------------------------------#
#### National Variable Numbers and Evaluation: Q2 GDP
####----------------------------------------------------------#
# summary of OLS results
cat("### Summary of OLS Results:\n")
print(summary(reg_econ_2))
cat("\n")

# correlation between popular vote and Q2 GDP
cat("### Correlation Between Popular Vote and Q2 GDP:\n")
correlation <- cor(d_inc_econ_2$GDP_growth_quarterly, d_inc_econ_2$pv2p)
print(correlation)
cat("\n")

# evaluate the in-sample fit/ r squared
cat("### In-Sample Fit (R-squared):\n")
r_squared <- summary(reg_econ_2)$r.squared
print(r_squared)
cat("\n")

# plot residuals
plot(d_inc_econ_2$year, d_inc_econ_2$pv2p, type = "l",
     main = "Residual Plot: True Y (Line), Predicted Y (dot) for Each Year",
     xlab = "Year", 
     ylab = "National Popular Vote Share")
points(d_inc_econ_2$year, predict(reg_econ_2, d_inc_econ_2), col = "purple")

# MSE, hard to interpret on its own, need to compare to other models
cat("### Mean Squared Error (MSE):\n")
mse <- mean((reg_econ_2$model$pv2p - reg_econ_2$fitted.values)^2)
print(mse)
cat("\n")

# RMSE, helpful with outliers
cat("### Root Mean Squared Error (RMSE):\n")
rmse <- sqrt(mse)
print(rmse)
cat("\n")

# Model Testing: Cross-Validation (1000 Runs)
out_samp_errors <- sapply(1:1000, function(i) {
  years_out_samp <- sample(d_inc_econ_2$year, 9) 
  mod <- lm(pv2p ~ GDP_growth_quarterly, 
            d_inc_econ_2[!(d_inc_econ_2$year %in% years_out_samp),])
  out_samp_pred <- predict(mod, d_inc_econ_2[d_inc_econ_2$year %in% years_out_samp,])
  out_samp_truth <- d_inc_econ_2$pv2p[d_inc_econ_2$year %in% years_out_samp]
  mean(out_samp_pred - out_samp_truth)
})

cat("### Mean Absolute Cross-Validation Error:\n")
mean_abs_error <- mean(abs(out_samp_errors))
print(mean_abs_error)
cat("\n")

hist(out_samp_errors, main = "Histogram of Cross-Validation Errors Q2 GDP",
     xlab = "Cross-Validation Error", ylab = "Frequency")
```

```{r, include = FALSE}
####----------------------------------------------------------#
#### 2024 Prediction: Q2 GDP National
####----------------------------------------------------------#
# Sequester 2024 data.
GDP_new <- d_fred |> 
  filter(year == 2024 & quarter == 2) |> 
  select(GDP_growth_quarterly)

# Predict uncertainty.
# makes 95% confidence interval unknown what type of distribution 
predict(reg_econ_2, GDP_new, interval = "prediction")
```

```{r}
####----------------------------------------------------------#
#### National Variable Scatterplot: Q2 RDPI growth
####----------------------------------------------------------#

# fit a bivariate OLS to the data
reg_econ_2 <- lm(pv2p ~ RDPI_growth_quarterly, 
                         data = d_inc_econ_2)

# scatterplot of RDPI growth versus pv2p
scatterplot_rdpi_growth <- d_inc_econ_2 |> 
  ggplot(aes(x = RDPI_growth_quarterly, y = pv2p, label = year)) + 
  geom_text(aes(label = year, text = paste("RDPI Growth:", round(RDPI_growth_quarterly,3), "<br>Popular Vote:", round(pv2p,3))), 
            nudge_x = 0.02, nudge_y = 0.02, check_overlap = TRUE) + 
  geom_smooth(method = "lm", formula = y ~ x, color = "green", fill = "lightgreen", show.legend = FALSE) +
  geom_hline(yintercept = 50, lty = 2) + 
  geom_vline(xintercept = 0.01, lty = 2) + 
  labs(x = "Second Quarter RDPI Growth (%)", 
       y = "Incumbent Party's National Popular Vote Share", 
       title = "Q2 RDPI Growth vs Incumbent National Popular Vote Share") + 
  scatterplot_theme

# convert to plotly
scatterplot_interactive <- ggplotly(scatterplot_rdpi_growth, tooltip = "text")

# handle odd smooth highlighting 
scatterplot_interactive <- scatterplot_interactive %>%
  style(
    hoverinfo = "text", 
    traces = which(sapply(scatterplot_interactive$x$data, function(trace) "text" %in% names(trace)))
  ) %>%
  layout(
    hovermode = "closest"
  )

scatterplot_interactive
```

```{r, include = FALSE}
####----------------------------------------------------------#
#### National Variable Numbers and Evaluation: Q2 RDPI growth
####----------------------------------------------------------#
# summary of OLS results
cat("### Summary of OLS Results:\n")
print(summary(reg_econ_2))
cat("\n")

# correlation between popular vote and Q2 RDPI
cat("### Correlation Between Popular Vote and Q2 RDPI growth:\n")
correlation <- cor(d_inc_econ_2$RDPI_growth_quarterly, d_inc_econ_2$pv2p)
print(correlation)
cat("\n")

# evaluate the in-sample fit/ r squared
cat("### In-Sample Fit (R-squared):\n")
r_squared <- summary(reg_econ_2)$r.squared
print(r_squared)
cat("\n")

# plot residuals
plot(d_inc_econ_2$year, d_inc_econ_2$pv2p, type = "l",
     main = "Residual Plot: True Y (Line), Predicted Y (dot) for Each Year",
     xlab = "Year", 
     ylab = "National Popular Vote Share")
points(d_inc_econ_2$year, predict(reg_econ_2, d_inc_econ_2), col = "purple")

# MSE, hard to interpret on its own, need to compare to other models
cat("### Mean Squared Error (MSE):\n")
mse <- mean((reg_econ_2$model$pv2p - reg_econ_2$fitted.values)^2)
print(mse)
cat("\n")

# RMSE, helpful with outliers
cat("### Root Mean Squared Error (RMSE):\n")
rmse <- sqrt(mse)
print(rmse)
cat("\n")

# Model Testing: Cross-Validation (1000 Runs)
out_samp_errors <- sapply(1:1000, function(i) {
  years_out_samp <- sample(d_inc_econ_2$year, 9) 
  mod <- lm(pv2p ~ RDPI_growth_quarterly, 
            d_inc_econ_2[!(d_inc_econ_2$year %in% years_out_samp),])
  out_samp_pred <- predict(mod, d_inc_econ_2[d_inc_econ_2$year %in% years_out_samp,])
  out_samp_truth <- d_inc_econ_2$pv2p[d_inc_econ_2$year %in% years_out_samp]
  mean(out_samp_pred - out_samp_truth)
})

cat("### Mean Absolute Cross-Validation Error:\n")
mean_abs_error <- mean(abs(out_samp_errors))
print(mean_abs_error)
cat("\n")

hist(out_samp_errors, main = "Histogram of Cross-Validation Errors Q2 RDPI",
     xlab = "Cross-Validation Error", ylab = "Frequency")
```


```{r, include = FALSE}
####----------------------------------------------------------#
#### 2024 Prediction: Q2 RDPI growth National
####----------------------------------------------------------#
# Sequester 2024 data.
RDPI_growth_new <- d_fred |> 
  filter(year == 2024 & quarter == 2) |> 
  select(RDPI_growth_quarterly)

# Predict uncertainty.
# makes 95% confidence interval unknown what type of distribution 
predict(reg_econ_2, RDPI_growth_new, interval = "prediction")
```

Analyzing the fit of these two bivariate regression models, it is important to note that neither is particularly strong objectively, as evidenced by the in sample fit. Using RDPI growth only accounts for 11.15% of the variance in incumbent popular vote share($R^2$ metric). Quarter two GDP growth does slightly better, explaining for 32.48% of the variation. While, as I will show below, these are the top two predictors in terms of in-sample fit of the national economic variables described, their overall performance does not indicate strong predictive power. 

Additionally, looking at the correlation between these predictors and the popular vote outcomes 1952-2016, both have a moderately strong positive correlation (0.569918 for GDP growth and 0.3338966 for RDPI growth). However, correlation does not imply causation, and as such there is little evidence for a direct causal relationship between either of these economic indicators and popular vote share on their own. There are likely additional omitted variables that I cannot control, as well as  a multivariate relationship possible. It is also worth noting that these models do even worse when including 2020, an outlier year in economic metrics. 

A summary of the relationships between these and other national economic variables used as predictors is shown below.

```{r}
####----------------------------------------------------------#
#### Table of all results for comparison
####----------------------------------------------------------#

# define the function to fit the regression model and compute statistics so it can be in one table
get_variable_summary <- function(variable, data, new_data) {
  # remove rows with NA values in the variable and pv2p columns
  data_clean <- data %>%
    filter(!is.na(!!sym(variable)), !is.na(pv2p))
  
  # fit bivariate regression model
  model <- lm(as.formula(paste("pv2p ~", variable)), data = data_clean)
  model_summary <- summary(model)
  
  # compute statistics for regression
  intercept <- coef(model)["(Intercept)"]
  slope <- coef(model)[variable]
  r_squared <- model_summary$r.squared
  correlation <- cor(data_clean[[variable]], data_clean$pv2p)
  
  # predict for pv2p 2024
  prediction <- predict(model, newdata = new_data, interval = "prediction")
  
  # compute mse and rmse errors
  mse <- mean((model$model$pv2p - model$fitted.values)^2)
  rmse <- sqrt(mse)
  
  # cross-validation
  out_samp_errors <- sapply(1:1000, function(i) {
    years_out_samp <- sample(data_clean$year, min(9, nrow(data_clean) - 1), replace = FALSE)
    mod <- lm(as.formula(paste("pv2p ~", variable)), 
              data_clean[!(data_clean$year %in% years_out_samp),])
    out_samp_pred <- predict(mod, data_clean[data_clean$year %in% years_out_samp,])
    out_samp_truth <- data_clean$pv2p[data_clean$year %in% years_out_samp]
    mean(out_samp_pred - out_samp_truth)
  })
  mean_abs_error <- mean(abs(out_samp_errors))
  
  # create result tibble
  tibble(
    variable = variable,
    r_squared = r_squared,
    prediction_2024 = prediction[1, "fit"],
    prediction_2024_upper = prediction[1, "upr"],
    prediction_2024_lower = prediction[1, "lwr"],
    mean_abs_error = mean_abs_error,
    rmse = rmse,
    correlation = correlation,
    slope = slope,
    intercept = intercept
  )
}


# list of variables to analyze
variables <- c("GDP", "GDP_growth_quarterly", "RDPI", "RDPI_growth_quarterly", 
               "CPI", "unemployment", "sp500_open", "sp500_high", "sp500_low", 
               "sp500_close", "sp500_adj_close", "sp500_volume", "dpi")

# prepare 2024 data for prediction
new_data_list <- map(variables, function(var) {
  if (var == "dpi") {
    # special handling for dpi because it is in bea not fred
    d_bea %>%
      filter(year == 2024 & quarter == "Q2") %>%
      select(all_of(var))
  } else {
    d_fred %>%
      filter(year == 2024 & quarter == 2) %>%
      select(all_of(var))
  }
})

# create a table with all results
results <- map2_df(variables, new_data_list, ~get_variable_summary(.x, d_inc_econ_2, .y))

results <- results %>%
  mutate(across(where(is.numeric), ~round(.x, 3)))

kable(results) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

# help from chat gpt on creating the function and map2_df

```


Evaluating each of these models indicates that none are particularly strong in their ability to describe the incumbent popular vote data over time or significant in their ability to predict additional values for the 2024 election that indicate one winner over the other. While all 13 regressions predict Harris' popular vote percentage as the candidate for the incumbent party will be 44.216% to 51.973%, it is worth noting that all of the 95% confidence intervals for these values contain 50%, leading to results that are not significant. Additional factors are also needed to understand how Harris as the technical incumbent but not current president may fare within these models, a variable we cannot accurately reflect with these bivariate cases. 

While no model is particularly good, the best of the above is GDP growth for Q2 in the election year. It fares best in all methods of model evaluation, including in-sample fit with the highest $R^2$, smallest root mean squared error, and smallest mean absolute error after cross validation for out of sample fit. 

The 2024 prediction is also sensitive to the change in the predictive variable, pointing out that there may be some relationship between economic fundamentals and incumbent popular vote outcomes, as supported by the literature (LINK), but it may not be a direct bivariate one as the choice of predictor changes the model. This points to the important question of whether economic fundamentals have a direct or indirect effect on an individuals vote choice, as well as whether the national (sociotropic) or individual economic measures matter, an often explored phenomenon in the literature by scholars like [Gregory B. Markus of the University of Michigan](https://www.jstor.org/stable/2111314). 

### State Level Predictors
While sociotropic voting would point to national economic variables having a greater impact on the votes of the people and therefore the incumbent vote share, I will also investigate the potential impact of individual considerations. Some voters may take more into account person economic changes rather than national ones, and as such I will explore state level regressions with the predictor of unemployment rate to determine if this improves the predictive power compared to national data.

```{r, include = FALSE}
####----------------------------------------------------------#
#### Bring in state by state unemployment data
####----------------------------------------------------------#

# Create a named vector to map abbreviations to state names
state_abbreviations <- c(
  DATE = "date",
  ALURN = "alabama",
  ARURN = "arkansas",
  AZURN = "arizona",
  CAURN = "california",
  COURN = "colorado",
  CTURN = "connecticut",
  DCURN = "district of columbia",
  DEURN = "delaware",
  FLURN = "florida",
  GAURN = "georgia",
  IAURN = "iowa",
  IDURN = "idaho",
  ILURN = "illinois",
  INURN = "indiana",
  KSURN = "kansas",
  KYURN = "kentucky",
  LAURN = "louisiana",
  MAURN = "massachusetts",
  MDURN = "maryland",
  MEURN = "maine",
  MIURN = "michigan",
  MNURN = "minnesota",
  MOURN = "missouri",
  MSURN = "mississippi",
  MTURN = "montana",
  NCURN = "north carolina",
  NDURN = "north dakota",
  NEURN = "nebraska",
  NHURN = "new hampshire",
  NJURN = "new jersey",
  NMURN = "new mexico",
  NVURN = "nevada",
  NYURN = "new york",
  OHURN = "ohio",
  OKURN = "oklahoma",
  ORURN = "oregon",
  PAURN = "pennsylvania",
  RIURN = "rhode island",
  SCURN = "south carolina",
  SDURN = "south dakota",
  TNURN = "tennessee",
  TXURN = "texas",
  UTURN = "utah",
  VAURN = "virginia",
  VTURN = "vermont",
  WAURN = "washington",
  WIURN = "wisconsin",
  WVURN = "west virginia",
  WYURN = "wyoming"
)

unemp_state <- read_excel("C:/Users/Jacqui Schlesinger/Documents/election-blog1/Unemp.xls") # if you run this code please change to location of data to fit your set up, I am happy to provide this file as well!

# rename columns to match state names
colnames(unemp_state) <- state_abbreviations[colnames(unemp_state)]

# handle date format
unemp_state <- unemp_state %>%
  mutate(date = as.Date(date))

# handle the dates so to group by quarter and year soon
unemp_state <- unemp_state %>%
  mutate(
    year = year(date),
    quarter = quarter(date)
  )

# group and take the average
annual_quarterly_unemp <- unemp_state %>%
  group_by(year, quarter) %>%
  summarize(across(where(is.numeric), mean, na.rm = TRUE))

# get Q2 values in each election year
election_years <- c(1976, 1980, 1984, 1988, 1992, 1996, 2000, 2004, 2008, 2012, 2016, 2020, 2024)

d_unemp_q2 <- annual_quarterly_unemp %>%
  filter(quarter == 2 & year %in% election_years)

```

```{r, include = FALSE}
####----------------------------------------------------------#
#### Bring in state by state popular vote data
####----------------------------------------------------------#

d_pvstate_wide <- read_csv("C:/Users/Jacqui Schlesinger/Documents/election-blog1/clean_wide_state_2pv_1948_2020.csv") # if you run this code please change to location of data to fit your set up

d_pvstate_wide <- d_pvstate_wide %>%
  mutate(state = tolower(state))

# help from chat gpt on this one for how to transform the data correctly 

# Define the president in office for the four years leading up to each election year
incumbents <- data.frame(
  year = c(1976, 1980, 1984, 1988, 1992, 1996, 2000, 2004, 2008, 2012, 2016, 2020),
  incumbent_party = c(
    "Republican",  # Ford (1972-1976)
    "Republican",  # Ford (1976-1980)
    "Republican",  # Reagan (1980-1984)
    "Republican",  # Reagan (1984-1988)
    "Republican",  # Bush (1988-1992)
    "Democratic",  # Clinton (1992-1996)
    "Democratic",  # Clinton (1996-2000)
    "Republican",  # Bush (2000-2004)
    "Republican",  # Bush (2004-2008)
    "Democratic",  # Obama (2008-2012)
    "Democratic",  # Obama (2012-2016)
    "Republican"  # Trump (2016-2020)
  )
)

d_pvstate_wide <- d_pvstate_wide %>%
  filter(year >= 1976)

d_pvstate_wide <- d_pvstate_wide %>%
  left_join(incumbents, by = "year")

d_pvstate_wide <- d_pvstate_wide %>%
  mutate(incumbent_pv2p = case_when(
    incumbent_party == "Democratic" ~ D_pv2p,
    incumbent_party == "Republican" ~ R_pv2p,
  ))

d_state_incumbent <- d_pvstate_wide %>%
  select(year, state, incumbent_pv2p)
```

```{r, include = FALSE}
####----------------------------------------------------------#
#### Join popular vote and unemployment data
####----------------------------------------------------------#

# get unemployment data in long format
d_unemp_q2_long <- d_unemp_q2 %>%
  pivot_longer(
    cols = starts_with("alabama"):starts_with("wyoming"),
    names_to = "state",
    values_to = "unemployment_rate"
  )

# join data together
d_state_data <- d_unemp_q2_long %>%
  inner_join(d_state_incumbent, by = c("year", "state"))

```

```{r}
####----------------------------------------------------------#
#### Regressions for each state
####----------------------------------------------------------#

# function to fit the model and extract R-squared and slope, used chatgpt for tibble part and cur_data from purrr
get_regression_stats <- function(data) {
  model <- lm(incumbent_pv2p ~ unemployment_rate, data = data)
  model_summary <- summary(model)
  
  tibble(
    r_squared = model_summary$r.squared,
    slope = coef(model)["unemployment_rate"],
    intercept = coef(model)["(Intercept)"],
    slope_se = sqrt(diag(vcov(model))["unemployment_rate"])
  )
}

# Perform regression for each state and summarize results
regression_summary <- d_state_data %>%
  group_by(state) %>%
  summarize(
    # Apply function to fit model and get statistics
    stats = list(get_regression_stats(cur_data())),
    .groups = 'drop'
  ) %>%
  unnest(stats)

# start handling data for mapping
regression_summary$region <- tolower(regression_summary$state)

# sequester shapefile of states from maps library
states_map <- map_data("state")

# join data from mapping 
states_with_stats <- regression_summary |>
  left_join(states_map, by = "region")

# create base ggplot
base_map <- states_with_stats %>%
  ggplot(aes(long, lat, group = group)) +
  geom_polygon(aes(fill = r_squared,
                   text = paste("State:", state,
                                "<br>R-squared:", round(r_squared, 2),
                                "<br>Standard Error:", round(slope_se, 2),
                                "<br>Pop Vote = ", round(intercept, 2), " + unemployment_rate * ", round(slope, 2))),
               color = "black") +
  ggtitle("Regression Statistics by State") + 
  scale_fill_gradient2(high = "darkgreen", 
                       mid = "lightgreen", 
                       low = "white", 
                       name = "In Sample Fit (R-Squared)") +
  maps_theme

# use plotly to make interactive
plotly_map <- ggplotly(base_map, tooltip = "text")
plotly_map
```

Visualizing the results of these 48 regressions above-- excluding Hawaii, Alaska, and Washington DC due to limitations with data available-- a similar variety of in sample fit values to that of the national economic fundamentals appears. While we are only looking at one predictor, which is specifically Q2 unemployment rate in each state in the election year 1976-2016, the predictive power correlationally is stronger than out best predictor on the national level in states like North Dakota and on the other hand near zero in states like Michigan. 

Because state level GDP growth data is not readily available, there is no way to test whether that particular predictor does better in a sociotropic or individual setting. The unemployment rate, here with an average in sample fit of 0.132, does much better than the near 0 variance explained by the national unemployment rate, but still points to GDP growth as the best predictor in this case. This is counter to some literature (LINK), which notes the RDPI growth is a much better predictor of incumbent popular vote, but those are not the results found here. 

```{r, include = FALSE}
####----------------------------------------------------------#
#### 2024 prediction based on the states
####----------------------------------------------------------#

# Step 1: Extract 2024 unemployment data and pivot to long format
d_unemp_2024 <- d_unemp_q2 %>%
  filter(year == 2024) %>%
  pivot_longer(
    cols = starts_with("alabama"):starts_with("wyoming"),
    names_to = "state",
    values_to = "unemployment_rate"
  )

# Step 2: Join with regression results to get slopes
# Assuming regression_summary contains state, r_squared, and slope
predictions_2024 <- d_unemp_2024 %>%
  left_join(regression_summary, by = "state") %>%
  mutate(
    # Calculate the predicted popular vote
    predicted_pv2p = intercept + slope * unemployment_rate,
    
    # Calculate 95% confidence intervals
    ci_lower = predicted_pv2p - 1.96 * (slope_se * unemployment_rate),
    ci_upper = predicted_pv2p + 1.96 * (slope_se * unemployment_rate)
  )
predictions_2024
# Step 3: Calculate the average predicted popular vote for 2024
average_prediction <- predictions_2024 %>%
  summarize(
    average_predicted_pv2p = mean(predicted_pv2p, na.rm = TRUE),
    average_ci_lower = mean(ci_lower, na.rm = TRUE),
    average_ci_upper = mean(ci_upper, na.rm = TRUE)
  )

# Print the result
print(average_prediction)

```

It is worth noting that there are only twelve data points in each regression, most likely leading to over-fitting of these models. This is also a concern with the slightly larger group of national economic fundamentals data points and in general when creating models to predict election outcomes. The small number of applicable elections makes it difficult to fit a model that works well out of sample. 

### Individual Versus Sociotropic Voting Patterns
Given the results above, sociotropic voting, when people vote based on national economic conditions that effect others and not just themselves, is a more likely explanation in the retrospective economic voting model than is individual circumstance based voting. This is consistent with the importance of aggregate over individual conditions as found in (LINK).

It has also been shown in [Achen and Bartels' "Democracy for Realists: Why Elections Do Not Produce Responsive Government"](https://muse-jhu-edu.ezp-prod1.hul.harvard.edu/book/64646) that voters may be retrospective but focus on short terms before elections in order to evaluate their choices, consistent with our choice of Q2 election year metric. As [scholars Lenz and Healy](https://www.journals.uchicago.edu/doi/abs/10.1086/692785) note, this focus on the economy only during election years may select for the best economic manipulators, not leaders, but never-the-less provides insight on how voters use economic conditions to make decisions. 

It is also important to consider how predictors and trends in incumbent popular vote may have changed over the period we are examining. It could be that people used to behave retrospectively but perhaps don’t anymore because parties have moved in a way that people won’t flip between them anymore. Evidence from [Dassoneville and Tien's "Introduction to Forecasting the 2020 US Elections"](https://www.cambridge.org/core/journals/ps-political-science-and-politics/article/abs/introduction-to-forecasting-the-2020-us-elections/78235400F6BB7E2E370214D1A2307028) also highlights that economic variables may be effected by shocks which throw off the predictions, one reason why I decided to remove 2020 from all of my regressions above.


Taken together, this exploration and analysis of the literature leads to me use national GDP growth in quarter two before the election as the predictor in my forecast for 2024 results, leading to a prediction of two way popular vote of

**Current Forecast: Harris 51.585% - Trump 48.415%**

with a large margin of error and lack of significant result.

### Data Sources
- Popular Vote by Candidate, 1948-2020
- Popular Vote by State, 1948-2020
- FRED Economic Data, c.1927-2024
- BEA Economic Data, 1947-2024
- FRED Unemployment by State, 1976-2024